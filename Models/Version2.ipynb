{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "*Project:* Deep Active Inference\n",
    "\n",
    "*Author:* Jingwei Liu (Music department, UC San Diego)\n",
    "***\n",
    "\n",
    "# <span style=\"background-color:darkorange; color:white; padding:2px 6px\">Tutorial</span> \n",
    "\n",
    "\n",
    "# Version 2: DJ - Audience Model (guess action via limited past observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Actively choose my action for desired results\n",
    "\n",
    "* Adapt my mind to the true observation\n",
    "\n",
    "* Cannot experiment on the environment; guess action via limited past observations\n",
    "\n",
    "* Minimize under KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:pynput was not found; mouse and keyboard input will not be available.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scamp import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Flatten,Softmax,Input\n",
    "import keras.backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 20000) dtype=int32, numpy=\n",
       "array([[15, 12, 23, ..., 10, 13,  9],\n",
       "       [ 0,  1,  0, ...,  1,  0,  1]])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Species.csv', sep=\",\",index_col = 0)\n",
    "n = df.shape[0]\n",
    "X = tf.Variable(np.zeros((2,n*2)),dtype='int32')  # any data tensor\n",
    "for i in range(0,2*n,2):\n",
    "    X[0,i].assign(df['Cantus'][i/2] - 43)\n",
    "    X[1,i].assign(0)\n",
    "    X[0,i+1].assign(df['Counter'][i/2] - 55)\n",
    "    X[1,i+1].assign(1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20000, 31), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 30\n",
    "X = tf.concat([tf.one_hot(X[0,:], depth),tf.dtypes.cast(tf.reshape(X[1,:],[20000,1]),tf.float32)],1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(X[:18000,:])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(X[18000:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "window_length = n_steps\n",
    "dataset = test_dataset.window(window_length, shift=2, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "shuffle_dataset = dataset.shuffle(20000).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_model(batch_size,Type):\n",
    "    \n",
    "    rnn_units = 12\n",
    "    n_notes = 30\n",
    "\n",
    "    input_A = keras.layers.Input(shape=(None,31), name=\"input_A\") # (15, 20, 31)\n",
    "    input_B = keras.layers.Input(shape=(1,31), name=\"input_B\") # (15, 1, 31)\n",
    "\n",
    "    hidden1 = keras.layers.LSTM(rnn_units, return_sequences=True)(input_A) # (15,20,12)\n",
    "    hidden2 = keras.layers.LSTM(rnn_units, return_sequences=True)(hidden1) #(15,20,12)\n",
    "    \n",
    "    output_RNN = keras.layers.Dense(n_notes, activation='softmax', name = 'output_RNN')(hidden2) #(15,20,30)\n",
    "\n",
    "    e = keras.layers.Dense(1, activation='tanh')(hidden2) #(15,20,1)\n",
    "    e = keras.layers.Reshape([-1])(e) #(15,20)\n",
    "\n",
    "    alpha = keras.layers.Activation('softmax')(e) #(15,20)\n",
    "    c = keras.layers.Permute([2, 1])(keras.layers.RepeatVector(rnn_units)(alpha)) #(15,20,12)\n",
    "    c = keras.layers.Multiply()([hidden2, c]) #(15,20,12)\n",
    "    c = keras.layers.Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c) #(15,12)\n",
    "\n",
    "    output_A = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_A')(c) #(15,30) (0, cantus)\n",
    "    reshape = tf.reshape(output_A,[-1,1,30]) # (15, 1, 30)\n",
    "    if Type == \"_0_1\":\n",
    "        zero = tf.reshape(tf.zeros(batch_size),[batch_size,1,1])\n",
    "        input_output_A = tf.concat((reshape,zero),2) # (15, 1, 31)  (0, cantus)\n",
    "    elif Type == \"_1_0\":\n",
    "        one = tf.reshape(tf.ones(batch_size),[batch_size,1,1])\n",
    "        input_output_A = tf.concat((reshape,one),2) # (15, 1, 31)  (0, cantus)\n",
    "\n",
    "    aux1 = keras.layers.SimpleRNN(rnn_units)(input_B, initial_state=c) #(15,12)\n",
    "    aux2 = keras.layers.SimpleRNN(rnn_units)(input_output_A, initial_state=c) #(15,12)\n",
    "    output_B1 = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_B1')(aux1) #(15,30) (1, counter)\n",
    "    output_B2 = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_B2')(aux2) #(15,30) (1, counter)\n",
    "\n",
    "    model = keras.models.Model([input_A, input_B], [output_RNN, output_A, output_B1, output_B2])\n",
    "    \n",
    "    aux_model1 = keras.models.Model([input_A, input_B], output_B1)\n",
    "    aux_model2 = keras.models.Model(input_A, [output_A, output_B2])\n",
    "    \n",
    "    sub_model1 = keras.models.Model(input_A, output_A)\n",
    "    sub_model2 = keras.models.Model(input_A, output_B2)\n",
    "    \n",
    "    att_model = keras.models.Model([input_A, input_B], alpha)\n",
    "    \n",
    "    return model,aux_model1,aux_model2,sub_model1,sub_model2,att_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_,aux_model1_0_1_,aux_model2_0_1_, sub_model1_0_1_,sub_model2_0_1_,att_model_0_1_ = creat_model(batch_size,'_0_1')\n",
    "model_1_0_,aux_model1_1_0_,aux_model2_1_0_, sub_model1_1_0_,sub_model2_1_0_,att_model_1_0_ = creat_model(batch_size,'_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_0_.load_weights('model_1_0_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('version2_model_0_1_step1_train1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('version2_model_0_1_step2_train1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('version2_model_0_1_step5_train1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('version2_model_0_1_step1_train1_random.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('version2_model_0_1_step2_train1_random.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('version2_model_0_1_step5_train1_random.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('version2_model_0_1_step5_train1_random_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('version2_model_0_1_step10_train1_random.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [[15. 15. 15. 15. 15. 15. 15. 15. 19. 19.]\n",
      " [15. 15. 15. 15. 15. 15. 15. 15. 15. 15.]\n",
      " [29. 29. 29. 29. 29. 15. 15. 15. 15. 15.]\n",
      " [10. 15. 15. 15. 10. 15. 15. 15. 15. 15.]\n",
      " [10. 10. 10. 10. 10. 15. 15. 15. 15. 15.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      " [10. 15. 15. 15. 10. 10. 15. 10. 15. 15.]\n",
      " [15. 15. 15. 15. 15. 15. 15. 15. 15. 15.]\n",
      " [10. 10. 10. 10. 10. 10. 15. 15. 15. 15.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      " [10. 15. 15. 15. 15. 15. 15. 15. 15. 15.]\n",
      " [15. 10. 10. 10. 15. 15. 15. 15. 15. 15.]\n",
      " [15. 15. 15. 15. 15. 15. 15. 15. 15. 15.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 10. 15.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 10. 15.]\n",
      " [15. 15. 15. 15. 15. 15. 15. 15. 24. 24.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 15. 15.]]\n",
      "observation: [[23. 23. 23. 23. 23. 23. 23. 23. 23. 23.]\n",
      " [23. 23. 23. 23. 23. 23. 23. 23. 23. 23.]\n",
      " [24. 24. 24. 24. 24. 24. 24. 24. 24. 24.]\n",
      " [19. 19. 19. 19. 19. 19. 19. 19. 23. 23.]\n",
      " [19. 19. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      " [10. 10. 13. 19. 19. 19. 19. 19. 19. 19.]\n",
      " [19. 19. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      " [24. 24. 24. 24. 23. 23. 23. 23. 23. 23.]\n",
      " [19. 19. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      " [10. 13. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      " [19. 23. 23. 23. 23. 23. 19. 23. 23. 23.]\n",
      " [19. 19. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      " [19. 19. 19. 19. 19. 23. 23. 23. 23. 23.]\n",
      " [13. 19. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      " [19. 19. 19. 19. 19. 19. 19. 19. 19. 19.]\n",
      " [24. 24. 24. 24. 24. 24. 23. 23. 28. 28.]\n",
      " [10. 10. 13. 13. 13. 19. 19. 19. 19. 19.]\n",
      " [19. 19. 19. 19. 19. 19. 19. 19. 19. 19.]]\n",
      "\n",
      "act/obv/(pred_obv_weight)       step0       step1       step2       step3       step4       step5       step6       step7       step8       step9sequence match\n",
      "   sequence015/23/(0.06)15/23/(0.07)15/23/(0.07)15/23/(0.07)15/23/(0.07)15/23/(0.07)15/23/(0.07)15/23/(0.07)19/23/(0.07)19/23/(0.07)        0.07\n",
      "   sequence115/23/(0.06)15/23/(0.06)15/23/(0.06)15/23/(0.06)15/23/(0.06)15/23/(0.07)15/23/(0.07)15/23/(0.06)15/23/(0.07)15/23/(0.07)        0.06\n",
      "   sequence229/24/(0.09)29/24/(0.09)29/24/(0.10)29/24/(0.10)29/24/(0.10)15/24/(0.10)15/24/(0.10)15/24/(0.10)15/24/(0.10)15/24/(0.10)        0.10\n",
      "   sequence310/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)10/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/23/(0.05)15/23/(0.06)        0.08\n",
      "   sequence410/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.09)10/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)        0.09\n",
      "   sequence510/10/(0.07)10/10/(0.07)10/13/(0.05)10/19/(0.07)10/19/(0.07)10/19/(0.07)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.08)        0.07\n",
      "   sequence610/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)10/19/(0.09)10/19/(0.09)15/19/(0.09)10/19/(0.09)15/19/(0.09)15/19/(0.09)        0.09\n",
      "   sequence715/24/(0.10)15/24/(0.09)15/24/(0.09)15/24/(0.09)15/23/(0.07)15/23/(0.07)15/23/(0.07)15/23/(0.07)15/23/(0.07)15/23/(0.07)        0.08\n",
      "   sequence810/19/(0.09)10/19/(0.09)10/19/(0.09)10/19/(0.09)10/19/(0.09)10/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)        0.09\n",
      "   sequence910/10/(0.08)10/13/(0.06)10/19/(0.07)10/19/(0.07)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.09)10/19/(0.09)        0.08\n",
      "  sequence1010/19/(0.09)15/23/(0.06)15/23/(0.06)15/23/(0.06)15/23/(0.06)15/23/(0.06)15/19/(0.09)15/23/(0.06)15/23/(0.06)15/23/(0.06)        0.07\n",
      "  sequence1115/19/(0.09)10/19/(0.09)10/19/(0.09)10/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)        0.09\n",
      "  sequence1215/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/19/(0.09)15/23/(0.06)15/23/(0.06)15/23/(0.06)15/23/(0.06)15/23/(0.06)        0.07\n",
      "  sequence1310/13/(0.05)10/19/(0.07)10/19/(0.07)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.09)10/19/(0.09)10/19/(0.09)15/19/(0.09)        0.08\n",
      "  sequence1410/19/(0.09)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.09)10/19/(0.09)10/19/(0.09)15/19/(0.09)        0.09\n",
      "  sequence1515/24/(0.10)15/24/(0.10)15/24/(0.09)15/24/(0.09)15/24/(0.10)15/24/(0.10)15/23/(0.07)15/23/(0.07)24/28/(0.07)24/28/(0.08)        0.09\n",
      "  sequence1610/10/(0.07)10/10/(0.07)10/13/(0.06)10/13/(0.05)10/13/(0.05)10/19/(0.06)10/19/(0.07)10/19/(0.07)10/19/(0.08)10/19/(0.08)        0.07\n",
      "  sequence1710/19/(0.07)10/19/(0.07)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.08)10/19/(0.09)10/19/(0.09)15/19/(0.09)15/19/(0.09)        0.08\n",
      "  step match        0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.08        0.08\n"
     ]
    }
   ],
   "source": [
    "# version 1/2 generate sequence\n",
    "\n",
    "seq_length = 10\n",
    "\n",
    "mode = \"max\"\n",
    "#mode = \"random\"\n",
    "\n",
    "for window in shuffle_dataset.take(1):\n",
    "    sequence = window\n",
    "    initial = window\n",
    "    \n",
    "    X0 = np.zeros((batch_size,10,31))\n",
    "    X1 = np.zeros((batch_size,10,31))\n",
    "    \n",
    "    action = np.zeros((batch_size,seq_length))\n",
    "    real_observation = np.zeros((batch_size,seq_length))\n",
    "    obv_weight = np.zeros((batch_size,seq_length))\n",
    "    \n",
    "    for s in range(seq_length):\n",
    "        for g in range(10):\n",
    "            X0[:,g,:] = initial[:,2*g,:]\n",
    "            X1[:,g,:] = initial[:,2*g+1,:]\n",
    "\n",
    "        [pred_o,a] = aux_model2_0_1_.predict(X0) #(18,30)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            if mode == \"max\":\n",
    "                action[i,s] = np.where(a[i,:] == np.max(a[i,:]))[0][0]\n",
    "            elif mode == \"random\":\n",
    "                action[i,s] = np.random.choice(30, 1, p=a[i,:])[0]\n",
    "\n",
    "        \n",
    "        one_hot = tf.one_hot(action[:,s], 30) #(18,30)\n",
    "\n",
    "        reshape = tf.reshape(one_hot,[batch_size,1,30])\n",
    "        one = tf.reshape(tf.ones(batch_size),[batch_size,1,1])\n",
    "        input_action = tf.concat((reshape,one),2) # (18, 1, 31)  (1, counter)\n",
    "\n",
    "        real_o = aux_model1_1_0_.predict((X1, input_action)) # my action on environment; (18,30) real observation\n",
    "\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            if mode == \"max\":\n",
    "                real_observation[i,s] = np.where(real_o[i,:] == np.max(real_o[i,:]))[0][0]\n",
    "            elif mode == \"random\":\n",
    "                real_observation[i,s] = np.random.choice(30, 1, p=real_o[i,:])[0]\n",
    "            \n",
    "            index = int(real_observation[i,s])\n",
    "            obv_weight[i,s] = pred_o[i,index]\n",
    "\n",
    "        one_hot = tf.one_hot(real_observation[:,s], 30) #(18,30)\n",
    "\n",
    "        reshape = tf.reshape(one_hot,[batch_size,1,30])\n",
    "        zero = tf.reshape(tf.zeros(batch_size),[batch_size,1,1])\n",
    "        input_observation = tf.concat((reshape,zero),2) # (18, 1, 31)  (1, counter)\n",
    "        \n",
    "        sequence = tf.concat((sequence,input_observation,input_action),1)\n",
    "        \n",
    "        initial = sequence[:,-20:,:]\n",
    "        \n",
    "  \n",
    "    print('action:',action)\n",
    "    print('observation:',real_observation)\n",
    "    print('')\n",
    "    \n",
    "    \n",
    "    step = [];\n",
    "    for j in range(seq_length):\n",
    "        step.append(\"step\" + str(j))\n",
    "    step.append(\"sequence match\")\n",
    "        \n",
    "    sample = [];\n",
    "    for i in range(batch_size):\n",
    "        sample.append(\"sequence\" + str(i))\n",
    "    sample.append(\"step match\")\n",
    "    \n",
    "    table = [];\n",
    "    for i in range(batch_size):\n",
    "        seq = [];\n",
    "        for j in range(seq_length):\n",
    "            seq.append(str(int(action[i,j])) + \"/\" + str(int(real_observation[i,j])) + \"/(\" + '%.2f'%(obv_weight[i,j]) + \")\")\n",
    "        match = np.sum(obv_weight[i,:])/seq_length\n",
    "        seq.append('%.2f'%(match))\n",
    "        table.append(seq)\n",
    "        \n",
    "    last_row = [];\n",
    "    for j in range(seq_length):\n",
    "        match = np.sum(obv_weight[:,j])/batch_size\n",
    "        last_row.append('%.2f'%(match))\n",
    "    total = np.sum(obv_weight)/(seq_length*batch_size)\n",
    "    last_row.append('%.2f'%(total))\n",
    "    table.append(last_row)\n",
    "    \n",
    "    format_row = \"{:>12}\" * (seq_length + 2)\n",
    "    print(format_row.format(\"act/obv/(pred_obv_weight)\", *step))\n",
    "    for team, row in zip(sample, table):\n",
    "        print(format_row.format(team, *row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 9\n",
    "music = tf.reshape(sequence[sample,:,:],[-1,31])\n",
    "#music = music[-20:,:]\n",
    "row,col = music.shape\n",
    "cantus_lst = [];\n",
    "counter_lst = [];\n",
    "for i in range(row):\n",
    "    clas = np.where(music[i,:-1] == 1)[0][0]\n",
    "    if music[i,-1] == 0:\n",
    "        cantus_lst.append(clas+43)\n",
    "    elif music[i,-1] == 1:\n",
    "        counter_lst.append(clas+55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57,\n",
       " 53,\n",
       " 48,\n",
       " 49,\n",
       " 48,\n",
       " 53,\n",
       " 52,\n",
       " 50,\n",
       " 47,\n",
       " 51,\n",
       " 60,\n",
       " 58,\n",
       " 58,\n",
       " 69,\n",
       " 64,\n",
       " 57,\n",
       " 66,\n",
       " 62,\n",
       " 57,\n",
       " 62]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantus_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61,\n",
       " 56,\n",
       " 57,\n",
       " 56,\n",
       " 60,\n",
       " 57,\n",
       " 55,\n",
       " 57,\n",
       " 59,\n",
       " 60,\n",
       " 69,\n",
       " 71,\n",
       " 66,\n",
       " 78,\n",
       " 67,\n",
       " 60,\n",
       " 69,\n",
       " 65,\n",
       " 70,\n",
       " 66]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  3,  9,  7, 12,  4,  3,  7, 12,  9,  9, 13,  8,  9,  3,  3,  3,\n",
       "        3, 13,  4], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(counter_lst) - np.array(cantus_lst) # real harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5,   1,  -1,   4,  -3,  -2,   2,   2,   1,   9,   2,  -5,  12,\n",
       "       -11,  -7,   9,  -4,   5,  -4], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(counter_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4, -5,  1, -1,  5, -1, -2, -3,  4,  9, -2,  0, 11, -5, -7,  9, -4,\n",
       "       -5,  5], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(cantus_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preset Piano Merlin for piano\n",
      "Using preset Piano Merlin for piano\n"
     ]
    }
   ],
   "source": [
    "s = Session()\n",
    "s.tempo = 200\n",
    "piano1 = s.new_part(\"piano\")\n",
    "piano2 = s.new_part(\"piano\")\n",
    "\n",
    "def cantus():\n",
    "    for i in cantus_lst:\n",
    "        piano2.play_note(i,1,4)\n",
    "        \n",
    "def counter():\n",
    "    for i in counter_lst:\n",
    "        piano1.play_note(i,1,4)\n",
    "        \n",
    "        \n",
    "s.fast_forward_to_beat(100)\n",
    "\n",
    "s.start_transcribing()\n",
    "s.fork(counter)\n",
    "s.fork(cantus)\n",
    "s.wait_for_children_to_finish()\n",
    "performance = s.stop_transcribing()\n",
    "performance.to_score(title = \"First Species Counterpoint\", composer = \"My programme\",time_signature = \"4/4\").show_xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
