{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "*Project:* Deep Active Inference\n",
    "\n",
    "*Author:* Jingwei Liu (Music department, UC San Diego)\n",
    "***\n",
    "\n",
    "# <span style=\"background-color:darkorange; color:white; padding:2px 6px\">Tutorial</span> \n",
    "\n",
    "\n",
    "# 12 Tone First Species Counterpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Rules:\n",
    "\n",
    "Rules for melodic lines:\n",
    "1. No note may be followed by the same note\n",
    "2. Each note may appear a maximum of 3 times in length of 10\n",
    "3. No more than 2 leaps larger than a 4th (>= 5) in length of 10\n",
    "4. Leaps larger than a 3rd (>=5) should be followed by a change of direction and a step-wise motion (1 or 2)\n",
    "\n",
    "Numerical restiction:\n",
    "5. Cantus range: G2 - C5 (43 - 72); Counterpoint range:  G3 - C6 (55 - 84)\n",
    "6. Valid melodic intervals: m2(1), M2(2), m3(3), M3(4), P4(5), P5(7), m6(8), P8(12)\n",
    "7. Valid harmonic intervals: m3(3), M3(4), P5(7), m6(8), M6(9), P8(12)\n",
    "\n",
    "Rules for harmonic counters:\n",
    "8. Max of 3 of the same harmonic interval in length of 10\n",
    "9. A perfect interval (P5 or P8) must be approached with countary motion and at least one of the voices moving by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:pynput was not found; mouse and keyboard input will not be available.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scamp import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Flatten,Softmax,Input\n",
    "import keras.backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cantus  Counter\n",
      "0         58       67\n",
      "1         66       69\n",
      "2         64       71\n",
      "3         68       76\n",
      "4         66       74\n",
      "...      ...      ...\n",
      "9995      64       72\n",
      "9996      56       60\n",
      "9997      57       61\n",
      "9998      61       65\n",
      "9999      56       64\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Species.csv', sep=\",\",index_col = 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df.shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 20000) dtype=int32, numpy=\n",
       "array([[15, 12, 23, ..., 10, 13,  9],\n",
       "       [ 0,  1,  0, ...,  1,  0,  1]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.Variable(np.zeros((2,n*2)),dtype='int32')  # any data tensor\n",
    "for i in range(0,2*n,2):\n",
    "    X[0,i].assign(df['Cantus'][i/2] - 43)\n",
    "    X[1,i].assign(0)\n",
    "    X[0,i+1].assign(df['Counter'][i/2] - 55)\n",
    "    X[1,i+1].assign(1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20000, 31), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 30\n",
    "X = tf.concat([tf.one_hot(X[0,:], depth),tf.dtypes.cast(tf.reshape(X[1,:],[20000,1]),tf.float32)],1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(X[:16000,:])\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(X[16000:19000,:])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(X[19000:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "batch_size = 18\n",
    "window_length = n_steps\n",
    "dataset = test_dataset.window(window_length, shift=2, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "shuffle_dataset = dataset.shuffle(20000).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_model(batch_size,Type):\n",
    "    \n",
    "    rnn_units = 12\n",
    "    n_notes = 30\n",
    "\n",
    "    input_A = keras.layers.Input(shape=(None,31), name=\"input_A\") # (15, 20, 31)\n",
    "    input_B = keras.layers.Input(shape=(1,31), name=\"input_B\") # (15, 1, 31)\n",
    "\n",
    "    hidden1 = keras.layers.LSTM(rnn_units, return_sequences=True)(input_A) # (15,20,12)\n",
    "    hidden2 = keras.layers.LSTM(rnn_units, return_sequences=True)(hidden1) #(15,20,12)\n",
    "    \n",
    "    output_RNN = keras.layers.Dense(n_notes, activation='softmax', name = 'output_RNN')(hidden2) #(15,20,30)\n",
    "\n",
    "    e = keras.layers.Dense(1, activation='tanh')(hidden2) #(15,20,1)\n",
    "    e = keras.layers.Reshape([-1])(e) #(15,20)\n",
    "\n",
    "    alpha = keras.layers.Activation('softmax')(e) #(15,20)\n",
    "    c = keras.layers.Permute([2, 1])(keras.layers.RepeatVector(rnn_units)(alpha)) #(15,20,12)\n",
    "    c = keras.layers.Multiply()([hidden2, c]) #(15,20,12)\n",
    "    c = keras.layers.Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c) #(15,12)\n",
    "\n",
    "    output_A = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_A')(c) #(15,30) (0, cantus)\n",
    "    reshape = tf.reshape(output_A,[-1,1,30]) # (15, 1, 30)\n",
    "    if Type == \"_0_1\":\n",
    "        zero = tf.reshape(tf.zeros(batch_size),[batch_size,1,1])\n",
    "        input_output_A = tf.concat((reshape,zero),2) # (15, 1, 31)  (0, cantus)\n",
    "    elif Type == \"_1_0\":\n",
    "        one = tf.reshape(tf.ones(batch_size),[batch_size,1,1])\n",
    "        input_output_A = tf.concat((reshape,one),2) # (15, 1, 31)  (0, cantus)\n",
    "\n",
    "    aux1 = keras.layers.SimpleRNN(rnn_units)(input_B, initial_state=c) #(15,12)\n",
    "    aux2 = keras.layers.SimpleRNN(rnn_units)(input_output_A, initial_state=c) #(15,12)\n",
    "    output_B1 = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_B1')(aux1) #(15,30) (1, counter)\n",
    "    output_B2 = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_B2')(aux2) #(15,30) (1, counter)\n",
    "\n",
    "    model = keras.models.Model([input_A, input_B], [output_RNN, output_A, output_B1, output_B2])\n",
    "    \n",
    "    aux_model1 = keras.models.Model([input_A, input_B], output_B1)\n",
    "    aux_model2 = keras.models.Model(input_A, [output_A, output_B2])\n",
    "    \n",
    "    sub_model1 = keras.models.Model(input_A, output_A)\n",
    "    sub_model2 = keras.models.Model(input_A, output_B2)\n",
    "    \n",
    "    att_model = keras.models.Model([input_A, input_B], alpha)\n",
    "    \n",
    "    return model,aux_model1,aux_model2,sub_model1,sub_model2,att_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_,aux_model1_0_1_,aux_model2_0_1_, sub_model1_0_1_,sub_model2_0_1_,att_model_0_1_ = creat_model(batch_size,'_0_1')\n",
    "model_1_0_,aux_model1_1_0_,aux_model2_1_0_, sub_model1_1_0_,sub_model2_1_0_,att_model_1_0_ = creat_model(batch_size,'_1_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_A (InputLayer)            [(None, None, 31)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 12)     2112        input_A[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 12)     1200        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 1)      13          lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, None)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None)         0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 12, None)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, None, 12)     0           repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 12)     0           lstm_1[0][0]                     \n",
      "                                                                 permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 12)           0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_A (Dense)                (None, 30)           390         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 1, 30)]      0           output_A[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_B (InputLayer)            [(None, 1, 31)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(18, 1, 31)]        0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn (SimpleRNN)          (None, 12)           528         input_B[0][0]                    \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)        (18, 12)             528         tf_op_layer_concat[0][0]         \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "output_RNN (Dense)              (None, None, 30)     390         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "output_B1 (Dense)               (None, 30)           390         simple_rnn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output_B2 (Dense)               (18, 30)             390         simple_rnn_1[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 5,941\n",
      "Trainable params: 5,941\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0_1_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('model_0_1_weight.h5')\n",
    "model_1_0_.load_weights('model_1_0_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collective_action: [[24. 26. 23. 20. 15. 22. 16. 13. 13. 17.]\n",
      " [ 9.  8. 15.  7.  9. 11. 23. 13. 17. 11.]\n",
      " [23. 18. 18. 23. 24. 27. 20. 22. 18. 21.]\n",
      " [ 0. 11. 14. 12. 14. 18. 15. 11. 16. 16.]\n",
      " [15. 18.  9. 12. 13. 14.  9. 14. 14. 11.]\n",
      " [13.  9. 14.  7.  6.  6. 12. 11.  8. 15.]\n",
      " [13. 22. 12.  9. 17. 15. 18. 17. 21. 23.]\n",
      " [12. 16.  4.  3. 10.  9.  8.  4.  0.  4.]\n",
      " [13.  5.  7.  3.  0.  5.  6.  8.  6.  9.]\n",
      " [ 9.  7.  3. 10. 11.  8.  7. 13.  8.  9.]\n",
      " [ 4.  2.  3.  8. 15.  7. 17. 16. 11. 18.]\n",
      " [18. 16. 15. 10.  7.  8. 14. 14. 15. 13.]\n",
      " [ 3.  0.  9.  1.  1.  5.  9.  0.  6.  7.]\n",
      " [18. 16. 24. 17. 17. 15. 17. 18. 16. 15.]\n",
      " [ 2.  5.  5.  7.  6.  1.  2. 11. 13. 12.]\n",
      " [17.  4.  8. 15. 13. 10. 15.  9.  9. 14.]\n",
      " [16. 17. 11. 10. 12. 15. 12. 15. 17. 21.]\n",
      " [ 3. 10. 12. 11. 17. 14. 14. 20. 25. 10.]]\n",
      "collective_observation: [[26. 27. 27. 28. 25. 22. 18. 17. 13. 19.]\n",
      " [13. 15. 11. 16. 19. 22. 17. 20. 15. 15.]\n",
      " [22. 19. 25. 29. 26. 22. 24. 26. 29. 23.]\n",
      " [17. 15. 18. 17. 19. 21. 24. 23. 23. 27.]\n",
      " [20. 22. 18. 14. 11. 14. 22. 20. 16. 21.]\n",
      " [19. 18. 24. 20. 20. 16. 11. 13. 20. 15.]\n",
      " [25. 19. 22. 22. 18. 22. 20. 23. 29. 24.]\n",
      " [ 5.  9.  9. 13. 15. 13. 14. 11. 15. 13.]\n",
      " [11. 11. 10.  9.  9. 12. 13. 12. 14. 14.]\n",
      " [15. 14. 16. 14.  9. 11. 15. 16. 20. 19.]\n",
      " [ 8. 12. 15. 15. 12. 17. 18. 23. 25. 24.]\n",
      " [29. 24. 26. 21. 17. 22. 21. 20. 27. 20.]\n",
      " [ 7.  9. 10. 12. 14. 14. 12. 15.  8. 14.]\n",
      " [29. 27. 24. 22. 24. 22. 21. 21. 18. 20.]\n",
      " [16. 13. 11. 10.  9. 14. 18. 18. 17. 23.]\n",
      " [14. 16. 13. 18. 15. 13. 16. 13. 17. 14.]\n",
      " [20. 19. 23. 22. 15. 19. 21. 21. 17. 18.]\n",
      " [14. 19. 15. 27. 27. 23. 23. 24. 19. 15.]]\n",
      "\n",
      "act/(pred_act_weight)      step0      step1      step2      step3      step4      step5      step6      step7      step8      step9sequence match\n",
      "  sequence0  24/(0.04)  26/(0.03)  23/(0.09)  20/(0.12)  15/(0.03)  22/(0.06)  16/(0.09)  13/(0.08)  13/(0.10)  17/(0.05)       0.07\n",
      "  sequence1   9/(0.08)   8/(0.08)  15/(0.03)   7/(0.10)   9/(0.11)  11/(0.10)  23/(0.00)  13/(0.10)  17/(0.06)  11/(0.10)       0.08\n",
      "  sequence2  23/(0.06)  18/(0.10)  18/(0.10)  23/(0.06)  24/(0.10)  27/(0.01)  20/(0.11)  22/(0.07)  18/(0.10)  21/(0.11)       0.08\n",
      "  sequence3   0/(0.03)  11/(0.07)  14/(0.05)  12/(0.11)  14/(0.11)  18/(0.05)  15/(0.10)  11/(0.04)  16/(0.09)  16/(0.10)       0.07\n",
      "  sequence4  15/(0.11)  18/(0.07)   9/(0.03)  12/(0.10)  13/(0.08)  14/(0.06)   9/(0.08)  14/(0.11)  14/(0.11)  11/(0.10)       0.08\n",
      "  sequence5  13/(0.07)   9/(0.08)  14/(0.10)   7/(0.02)   6/(0.02)   6/(0.03)  12/(0.07)  11/(0.07)   8/(0.09)  15/(0.07)       0.06\n",
      "  sequence6  13/(0.05)  22/(0.05)  12/(0.07)   9/(0.02)  17/(0.08)  15/(0.10)  18/(0.10)  17/(0.10)  21/(0.07)  23/(0.07)       0.07\n",
      "  sequence7  12/(0.01)  16/(0.00)   4/(0.06)   3/(0.07)  10/(0.06)   9/(0.11)   8/(0.06)   4/(0.07)   0/(0.06)   4/(0.10)       0.06\n",
      "  sequence8  13/(0.07)   5/(0.10)   7/(0.10)   3/(0.09)   0/(0.06)   5/(0.12)   6/(0.09)   8/(0.11)   6/(0.09)   9/(0.11)       0.09\n",
      "  sequence9   9/(0.05)   7/(0.07)   3/(0.04)  10/(0.08)  11/(0.07)   8/(0.09)   7/(0.10)  13/(0.06)   8/(0.07)   9/(0.10)       0.07\n",
      " sequence10   4/(0.13)   2/(0.13)   3/(0.10)   8/(0.07)  15/(0.03)   7/(0.09)  17/(0.03)  16/(0.07)  11/(0.05)  18/(0.09)       0.08\n",
      " sequence11  18/(0.09)  16/(0.06)  15/(0.09)  10/(0.02)   7/(0.02)   8/(0.04)  14/(0.10)  14/(0.11)  15/(0.11)  13/(0.04)       0.07\n",
      " sequence12   3/(0.14)   0/(0.11)   9/(0.03)   1/(0.08)   1/(0.05)   5/(0.09)   9/(0.09)   0/(0.03)   6/(0.08)   7/(0.10)       0.08\n",
      " sequence13  18/(0.10)  16/(0.05)  24/(0.06)  17/(0.09)  17/(0.10)  15/(0.09)  17/(0.09)  18/(0.10)  16/(0.10)  15/(0.10)       0.09\n",
      " sequence14   2/(0.08)   5/(0.07)   5/(0.09)   7/(0.11)   6/(0.10)   1/(0.07)   2/(0.09)  11/(0.05)  13/(0.09)  12/(0.10)       0.09\n",
      " sequence15  17/(0.05)   4/(0.03)   8/(0.10)  15/(0.02)  13/(0.11)  10/(0.09)  15/(0.04)   9/(0.08)   9/(0.09)  14/(0.08)       0.07\n",
      " sequence16  16/(0.09)  17/(0.10)  11/(0.05)  10/(0.04)  12/(0.10)  15/(0.06)  12/(0.07)  15/(0.09)  17/(0.10)  21/(0.03)       0.07\n",
      " sequence17   3/(0.12)  10/(0.06)  12/(0.10)  11/(0.11)  17/(0.09)  14/(0.05)  14/(0.06)  20/(0.06)  25/(0.02)  10/(0.02)       0.07\n",
      " step match       0.08       0.07       0.07       0.07       0.07       0.07       0.08       0.08       0.08       0.08       0.08\n",
      "\n",
      "obv/(pred_obv_weight)      step0      step1      step2      step3      step4      step5      step6      step7      step8      step9sequence match\n",
      "  sequence0  26/(0.12)  27/(0.15)  27/(0.15)  28/(0.14)  25/(0.11)  22/(0.10)  18/(0.06)  17/(0.06)  13/(0.03)  19/(0.10)       0.10\n",
      "  sequence1  13/(0.09)  15/(0.09)  11/(0.07)  16/(0.08)  19/(0.05)  22/(0.03)  17/(0.08)  20/(0.08)  15/(0.06)  15/(0.08)       0.07\n",
      "  sequence2  22/(0.09)  19/(0.06)  25/(0.07)  29/(0.10)  26/(0.14)  22/(0.06)  24/(0.10)  26/(0.11)  29/(0.13)  23/(0.09)       0.10\n",
      "  sequence3  17/(0.05)  15/(0.09)  18/(0.07)  17/(0.11)  19/(0.10)  21/(0.08)  24/(0.08)  23/(0.10)  23/(0.08)  27/(0.05)       0.08\n",
      "  sequence4  20/(0.09)  22/(0.08)  18/(0.07)  14/(0.06)  11/(0.04)  14/(0.08)  22/(0.03)  20/(0.09)  16/(0.07)  21/(0.08)       0.07\n",
      "  sequence5  19/(0.06)  18/(0.09)  24/(0.02)  20/(0.09)  20/(0.09)  16/(0.09)  11/(0.05)  13/(0.10)  20/(0.06)  15/(0.08)       0.07\n",
      "  sequence6  25/(0.09)  19/(0.07)  22/(0.09)  22/(0.09)  18/(0.09)  22/(0.08)  20/(0.07)  23/(0.09)  29/(0.07)  24/(0.11)       0.09\n",
      "  sequence7   5/(0.05)   9/(0.11)   9/(0.07)  13/(0.09)  15/(0.07)  13/(0.09)  14/(0.10)  11/(0.08)  15/(0.05)  13/(0.09)       0.08\n",
      "  sequence8  11/(0.06)  11/(0.09)  10/(0.10)   9/(0.11)   9/(0.11)  12/(0.10)  13/(0.08)  12/(0.09)  14/(0.09)  14/(0.09)       0.09\n",
      "  sequence9  15/(0.09)  14/(0.08)  16/(0.09)  14/(0.10)   9/(0.04)  11/(0.08)  15/(0.08)  16/(0.08)  20/(0.07)  19/(0.09)       0.08\n",
      " sequence10   8/(0.12)  12/(0.07)  15/(0.06)  15/(0.09)  12/(0.07)  17/(0.08)  18/(0.07)  23/(0.04)  25/(0.07)  24/(0.06)       0.07\n",
      " sequence11  29/(0.11)  24/(0.09)  26/(0.07)  21/(0.10)  17/(0.09)  22/(0.03)  21/(0.06)  20/(0.09)  27/(0.03)  20/(0.09)       0.08\n",
      " sequence12   7/(0.09)   9/(0.13)  10/(0.12)  12/(0.08)  14/(0.07)  14/(0.07)  12/(0.09)  15/(0.08)   8/(0.07)  14/(0.05)       0.08\n",
      " sequence13  29/(0.12)  27/(0.12)  24/(0.09)  22/(0.09)  24/(0.09)  22/(0.10)  21/(0.10)  21/(0.09)  18/(0.06)  20/(0.10)       0.10\n",
      " sequence14  16/(0.03)  13/(0.09)  11/(0.11)  10/(0.12)   9/(0.10)  14/(0.06)  18/(0.02)  18/(0.03)  17/(0.10)  23/(0.03)       0.07\n",
      " sequence15  14/(0.06)  16/(0.09)  13/(0.09)  18/(0.04)  15/(0.08)  13/(0.05)  16/(0.09)  13/(0.05)  17/(0.09)  14/(0.08)       0.07\n",
      " sequence16  20/(0.07)  19/(0.08)  23/(0.07)  22/(0.10)  15/(0.07)  19/(0.09)  21/(0.07)  21/(0.10)  17/(0.05)  18/(0.08)       0.08\n",
      " sequence17  14/(0.04)  19/(0.02)  15/(0.11)  27/(0.00)  27/(0.03)  23/(0.10)  23/(0.08)  24/(0.06)  19/(0.05)  15/(0.02)       0.05\n",
      " step match       0.08       0.09       0.09       0.09       0.08       0.08       0.07       0.08       0.07       0.08       0.08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq_length = 10\n",
    "\n",
    "#generate_mode = \"max\"\n",
    "generate_mode = \"random\"\n",
    "\n",
    "\n",
    "mode = \"first meet\"\n",
    "#mode = \"brain 1\"\n",
    "#mode = \"brain 2\"\n",
    "#mode = \"brain 1_inside\"\n",
    "#mode = \"brain 2_inside\"\n",
    "\n",
    "\n",
    "for window in shuffle_dataset.take(1):\n",
    "    sequence = window\n",
    "    initial = window\n",
    "    \n",
    "    pred_0_1_1 = np.zeros((batch_size,seq_length))\n",
    "    pred_0_1_0 = np.zeros((batch_size,seq_length))\n",
    "    pred2_0_1_1 = np.zeros((batch_size,seq_length))\n",
    "    \n",
    "    pred_1_0_0 = np.zeros((batch_size,seq_length))\n",
    "    pred_1_0_1 = np.zeros((batch_size,seq_length))\n",
    "    pred2_1_0_0 = np.zeros((batch_size,seq_length))\n",
    "    \n",
    "    obv_weight = np.zeros((batch_size,seq_length))\n",
    "    act_weight = np.zeros((batch_size,seq_length))\n",
    "\n",
    "    for s in range(seq_length):\n",
    "\n",
    "        [pred_o,a] = aux_model2_0_1_.predict(initial) #(18,30)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if generate_mode == \"max\":\n",
    "                pred_0_1_0[i,s] = np.where(pred_o[i,:] == np.max(pred_o[i,:]))[0][0]\n",
    "                pred_0_1_1[i,s] = np.where(a[i,:] == np.max(a[i,:]))[0][0]\n",
    "            elif generate_mode == \"random\":\n",
    "                pred_0_1_0[i,s] = np.random.choice(30, 1, p=pred_o[i,:])[0]\n",
    "                pred_0_1_1[i,s] = np.random.choice(30, 1, p=a[i,:])[0]\n",
    "\n",
    "\n",
    "        [pred_a,o] = aux_model2_1_0_.predict(initial) #(18,30)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            if generate_mode == \"max\":\n",
    "                pred_1_0_1[i,s] = np.where(pred_a[i,:] == np.max(pred_a[i,:]))[0][0]\n",
    "                pred_1_0_0[i,s] = np.where(o[i,:] == np.max(o[i,:]))[0][0]\n",
    "            elif generate_mode == \"random\":\n",
    "                pred_1_0_1[i,s] = np.random.choice(30, 1, p=pred_a[i,:])[0]\n",
    "                pred_1_0_0[i,s] = np.random.choice(30, 1, p=o[i,:])[0]\n",
    "            \n",
    "            index = int(pred_1_0_0[i,s])\n",
    "            obv_weight[i,s] = pred_o[i,index]\n",
    "            \n",
    "            index = int(pred_0_1_1[i,s])\n",
    "            act_weight[i,s] = pred_a[i,index]\n",
    "            \n",
    "        \n",
    "        one_hot = tf.one_hot(pred_0_1_0[:,s], 30) #(18,30)\n",
    "        reshape = tf.reshape(one_hot,[batch_size,1,30])\n",
    "        zero = tf.reshape(tf.zeros(batch_size),[batch_size,1,1])\n",
    "        out_0_1_0 = tf.concat((reshape,zero),2) # (18, 1, 31)  (1, counter)\n",
    "        \n",
    "        one_hot = tf.one_hot(pred_0_1_1[:,s], 30) #(18,30)\n",
    "        reshape = tf.reshape(one_hot,[batch_size,1,30])\n",
    "        one = tf.reshape(tf.ones(batch_size),[batch_size,1,1])\n",
    "        out_0_1_1 = tf.concat((reshape,one),2) # (18, 1, 31)  (1, counter)\n",
    "        \n",
    "        one_hot = tf.one_hot(pred_1_0_1[:,s], 30) #(18,30)\n",
    "        reshape = tf.reshape(one_hot,[batch_size,1,30])\n",
    "        one = tf.reshape(tf.ones(batch_size),[batch_size,1,1])\n",
    "        out_1_0_1 = tf.concat((reshape,one),2) # (18, 1, 31)  (1, counter)\n",
    "        \n",
    "        one_hot = tf.one_hot(pred_1_0_0[:,s], 30) #(18,30)\n",
    "        reshape = tf.reshape(one_hot,[batch_size,1,30])\n",
    "        zero = tf.reshape(tf.zeros(batch_size),[batch_size,1,1])\n",
    "        out_1_0_0 = tf.concat((reshape,zero),2) # (18, 1, 31)  (1, counter)\n",
    "\n",
    "        \n",
    "        a2 = aux_model1_0_1_.predict([initial,out_0_1_0])\n",
    "        o2 = aux_model1_1_0_.predict([initial,out_1_0_1])\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            if generate_mode == \"max\":\n",
    "                pred2_0_1_1[i,s] = np.where(a2[i,:] == np.max(a2[i,:]))[0][0]\n",
    "                pred2_1_0_0[i,s] = np.where(o2[i,:] == np.max(o2[i,:]))[0][0]\n",
    "            elif generate_mode == \"random\":\n",
    "                pred2_0_1_1[i,s] = np.random.choice(30, 1, p=a2[i,:])[0]\n",
    "                pred2_1_0_0[i,s] = np.random.choice(30, 1, p=o2[i,:])[0]\n",
    "\n",
    "        one_hot = tf.one_hot(pred2_0_1_1[:,s], 30) #(18,30)\n",
    "        reshape = tf.reshape(one_hot,[batch_size,1,30])\n",
    "        one = tf.reshape(tf.ones(batch_size),[batch_size,1,1])\n",
    "        out2_0_1_1 = tf.concat((reshape,one),2) # (18, 1, 31)  (1, counter)\n",
    "        \n",
    "        one_hot = tf.one_hot(pred2_1_0_0[:,s], 30) #(18,30)\n",
    "        reshape = tf.reshape(one_hot,[batch_size,1,30])\n",
    "        zero = tf.reshape(tf.zeros(batch_size),[batch_size,1,1])\n",
    "        out2_1_0_0 = tf.concat((reshape,zero),2) # (18, 1, 31)  (1, counter)\n",
    "        \n",
    "\n",
    "        if mode == \"first meet\":\n",
    "            sequence = tf.concat((sequence,out_1_0_0),1)\n",
    "            sequence = tf.concat((sequence,out_0_1_1),1)\n",
    "        elif mode == \"brain 1\":\n",
    "            sequence = tf.concat((sequence,out_0_1_0),1)\n",
    "            sequence = tf.concat((sequence,out2_0_1_1),1)\n",
    "        elif mode == \"brain 2\":\n",
    "            sequence = tf.concat((sequence,out2_1_0_0),1)\n",
    "            sequence = tf.concat((sequence,out_1_0_1),1)\n",
    "        elif mode == \"brain 1_inside\":\n",
    "            sequence = tf.concat((sequence,out_0_1_0),1)\n",
    "            sequence = tf.concat((sequence,out_0_1_1),1)\n",
    "        elif mode == \"brain 2_inside\":\n",
    "            sequence = tf.concat((sequence,out_1_0_0),1)\n",
    "            sequence = tf.concat((sequence,out_1_0_1),1)\n",
    "\n",
    "            \n",
    "        initial = sequence[:,-20:,:]\n",
    "    if mode == \"first meet\":    \n",
    "        print('collective_action:',pred_0_1_1)\n",
    "        print('collective_observation:',pred_1_0_0)\n",
    "        print('')\n",
    "        \n",
    "        step = [];\n",
    "        for j in range(seq_length):\n",
    "            step.append(\"step\" + str(j))\n",
    "        step.append(\"sequence match\")\n",
    "\n",
    "        sample = [];\n",
    "        for i in range(batch_size):\n",
    "            sample.append(\"sequence\" + str(i))\n",
    "        sample.append(\"step match\")\n",
    "\n",
    "        table = [];\n",
    "        for i in range(batch_size):\n",
    "            seq = [];\n",
    "            for j in range(seq_length):\n",
    "                seq.append(str(int(pred_0_1_1[i,j])) + \"/(\" + '%.2f'%(act_weight[i,j]) + \")\")\n",
    "            match_a = np.sum(act_weight[i,:])/seq_length\n",
    "            seq.append('%.2f'%(match_a))\n",
    "            table.append(seq)\n",
    "\n",
    "        last_row = [];\n",
    "        for j in range(seq_length):\n",
    "            match_a = np.sum(act_weight[:,j])/batch_size\n",
    "            last_row.append('%.2f'%(match_a))\n",
    "        total_a = np.sum(act_weight)/(seq_length*batch_size)\n",
    "        last_row.append('%.2f'%(total_a))\n",
    "        table.append(last_row)\n",
    "\n",
    "        format_row = \"{:>11}\" * (seq_length + 2)\n",
    "        print(format_row.format(\"act/(pred_act_weight)\", *step))\n",
    "        for team, row in zip(sample, table):\n",
    "            print(format_row.format(team, *row))\n",
    "\n",
    "        print('')\n",
    "\n",
    "        table2 = [];\n",
    "        for i in range(batch_size):\n",
    "            seq = [];\n",
    "            for j in range(seq_length):\n",
    "                seq.append(str(int(pred_1_0_0[i,j])) + \"/(\" + '%.2f'%(obv_weight[i,j]) + \")\")\n",
    "            match_o = np.sum(obv_weight[i,:])/seq_length\n",
    "            seq.append('%.2f'%(match_o))\n",
    "            table2.append(seq)\n",
    "\n",
    "        last_row = [];\n",
    "        for j in range(seq_length):\n",
    "            match_o = np.sum(obv_weight[:,j])/batch_size\n",
    "            last_row.append('%.2f'%(match_o))\n",
    "        total_o = np.sum(obv_weight)/(seq_length*batch_size)\n",
    "        last_row.append('%.2f'%(total_o))\n",
    "        table2.append(last_row)\n",
    "\n",
    "        format_row = \"{:>11}\" * (seq_length + 2)\n",
    "        print(format_row.format(\"obv/(pred_obv_weight)\", *step))\n",
    "        for team, row in zip(sample, table2):\n",
    "            print(format_row.format(team, *row))\n",
    "    elif mode == \"brain 1\":\n",
    "        print('musician1_action:',pred2_0_1_1)\n",
    "        print('musician1_observation:',pred_0_1_0)\n",
    "    elif mode == \"brain 2\":\n",
    "        print('musician2_action:',pred_1_0_1)\n",
    "        print('musician2_observation:',pred2_1_0_0)\n",
    "    elif mode == \"brain 1_inside\":\n",
    "        print('musician1_action_pred:',pred_0_1_1)\n",
    "        print('musician1_observation_pred:',pred_0_1_0)\n",
    "    elif mode == \"brain 2_inside\":\n",
    "        print('musician2_action_pred:',pred_1_0_1)\n",
    "        print('musician2_observation_pred:',pred_1_0_0)\n",
    "    print('')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample =7\n",
    "music = tf.reshape(sequence[sample,:,:],[-1,31])\n",
    "#music = music[-20:,:]\n",
    "row,col = music.shape\n",
    "cantus_lst = [];\n",
    "counter_lst = [];\n",
    "for i in range(row):\n",
    "    clas = np.where(music[i,:-1] == 1)[0][0]\n",
    "    if music[i,-1] == 0:\n",
    "        cantus_lst.append(clas+43)\n",
    "    elif music[i,-1] == 1:\n",
    "        counter_lst.append(clas+55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51,\n",
       " 55,\n",
       " 63,\n",
       " 61,\n",
       " 49,\n",
       " 51,\n",
       " 52,\n",
       " 56,\n",
       " 52,\n",
       " 51,\n",
       " 48,\n",
       " 52,\n",
       " 52,\n",
       " 56,\n",
       " 58,\n",
       " 56,\n",
       " 57,\n",
       " 54,\n",
       " 58,\n",
       " 56]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantus_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63,\n",
       " 59,\n",
       " 66,\n",
       " 65,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 59,\n",
       " 56,\n",
       " 58,\n",
       " 67,\n",
       " 71,\n",
       " 59,\n",
       " 58,\n",
       " 65,\n",
       " 64,\n",
       " 63,\n",
       " 59,\n",
       " 55,\n",
       " 59]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  4,  3,  4,  9,  8,  8,  3,  4,  7, 19, 19,  7,  2,  7,  8,  6,\n",
       "        5, -3,  3], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(counter_lst) - np.array(cantus_lst) # real harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4,   7,  -1,  -7,   1,   1,  -1,  -3,   2,   9,   4, -12,  -1,\n",
       "         7,  -1,  -1,  -4,  -4,   4], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(counter_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   8,  -2, -12,   2,   1,   4,  -4,  -1,  -3,   4,   0,   4,\n",
       "         2,  -2,   1,  -3,   4,  -2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(cantus_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preset Piano Merlin for piano\n",
      "Using preset Piano Merlin for piano\n"
     ]
    }
   ],
   "source": [
    "s = Session()\n",
    "s.tempo = 200\n",
    "piano1 = s.new_part(\"piano\")\n",
    "piano2 = s.new_part(\"piano\")\n",
    "\n",
    "def cantus():\n",
    "    for i in cantus_lst:\n",
    "        piano2.play_note(i,1,4)\n",
    "        \n",
    "def counter():\n",
    "    for i in counter_lst:\n",
    "        piano1.play_note(i,1,4)\n",
    "        \n",
    "        \n",
    "s.fast_forward_to_beat(100)\n",
    "\n",
    "s.start_transcribing()\n",
    "s.fork(counter)\n",
    "s.fork(cantus)\n",
    "s.wait_for_children_to_finish()\n",
    "performance = s.stop_transcribing()\n",
    "performance.to_score(title = \"First Species Counterpoint\", composer = \"My programme\",time_signature = \"4/4\").show_xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
