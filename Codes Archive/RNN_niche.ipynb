{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:pynput was not found; mouse and keyboard input will not be available.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scamp import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Flatten,Softmax,Input\n",
    "import keras.backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_model():\n",
    "    \n",
    "    rnn_units = 12\n",
    "    n_notes = 30\n",
    "\n",
    "    input_A = keras.layers.Input(shape=(20,31), name=\"input_A\") # (15, 20, 31)\n",
    "    input_B = keras.layers.Input(shape=(1,31), name=\"input_B\") # (15, 1, 31)\n",
    "\n",
    "    hidden1 = keras.layers.LSTM(rnn_units, return_sequences=True)(input_A) # (15,20,12)\n",
    "    hidden2 = keras.layers.LSTM(rnn_units, return_sequences=True)(hidden1) #(15,20,12)\n",
    "    \n",
    "    output_RNN = keras.layers.Dense(n_notes, activation='softmax', name = 'output_RNN')(hidden2) #(15,20,30)\n",
    "\n",
    "    e = keras.layers.Dense(1, activation='tanh')(hidden2) #(15,20,1)\n",
    "    e = keras.layers.Reshape([-1])(e) #(15,20)\n",
    "\n",
    "    alpha = keras.layers.Activation('softmax')(e) #(15,20)\n",
    "    c = keras.layers.Permute([2, 1])(keras.layers.RepeatVector(rnn_units)(alpha)) #(15,20,12)\n",
    "    c = keras.layers.Multiply()([hidden2, c]) #(15,20,12)\n",
    "    c = keras.layers.Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c) #(15,12)\n",
    "\n",
    "    output_A = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_A')(c) #(15,30) (0, cantus)\n",
    "\n",
    "    aux = keras.layers.SimpleRNN(rnn_units)(input_B, initial_state=c) #(15,12)\n",
    "    output_B = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_B')(aux) #(15,30) (1, counter)\n",
    "\n",
    "    model = keras.models.Model([input_A, input_B], [output_RNN, output_A, output_B])\n",
    "    aux_model = keras.models.Model([input_A, input_B], [output_A, output_B])\n",
    "    sub_model = keras.models.Model(input_A, output_A)\n",
    "    att_model = keras.models.Model([input_A, input_B], alpha)\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy','categorical_crossentropy'],\n",
    "              loss_weights=[0.2, 0.4, 0.4],optimizer=\"sgd\")\n",
    "    aux_model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "              optimizer=\"sgd\")\n",
    "    sub_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\")\n",
    "    return model,aux_model,sub_model,att_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_,aux_model_0_1_, sub_model_0_1_,att_model_0_1_ = creat_model()\n",
    "model_1_0_,aux_model_1_0_, sub_model_1_0_,att_model_1_0_ = creat_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_A (InputLayer)            [(None, 20, 31)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 20, 12)       2112        input_A[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 20, 12)       1200        lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20, 1)        13          lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 20)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 20)           0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 12, 20)       0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 20, 12)       0           repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 20, 12)       0           lstm_5[0][0]                     \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 12)           0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_B (InputLayer)            [(None, 1, 31)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)        (None, 12)           528         input_B[0][0]                    \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_RNN (Dense)              (None, 20, 30)       390         lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "output_A (Dense)                (None, 30)           390         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_B (Dense)                (None, 30)           390         simple_rnn_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 5,023\n",
      "Trainable params: 5,023\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0_1_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.load_weights('model_0_1_weight.h5')\n",
    "model_1_0_.load_weights('model_1_0_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 20000) dtype=int32, numpy=\n",
       "array([[15, 12, 23, ..., 10, 13,  9],\n",
       "       [ 0,  1,  0, ...,  1,  0,  1]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Species.csv', sep=\",\",index_col = 0)\n",
    "n = df.shape[0]\n",
    "X = tf.Variable(np.zeros((2,n*2)),dtype='int32')  # any data tensor\n",
    "for i in range(0,2*n,2):\n",
    "    X[0,i].assign(df['Cantus'][i/2] - 43)\n",
    "    X[1,i].assign(0)\n",
    "    X[0,i+1].assign(df['Counter'][i/2] - 55)\n",
    "    X[1,i+1].assign(1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20000, 31), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 30\n",
    "X = tf.concat([tf.one_hot(X[0,:], depth),tf.dtypes.cast(tf.reshape(X[1,:],[20000,1]),tf.float32)],1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(10000, 31) dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observation only\n",
    "X0 = tf.Variable(np.zeros((n,31)),dtype='float32')\n",
    "for i in range(n):\n",
    "    X0[i,:].assign(X[2*i,:])\n",
    "X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(X0[:9600,:])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(X0[9600:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "window_length = n_steps\n",
    "dataset = train_dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "shuffle_dataset = dataset.shuffle(10000).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "(20, 10, 31)\n",
      "479\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for window in shuffle_dataset:\n",
    "    i = i + 1\n",
    "    print(window.shape)\n",
    "    #print(window)\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20, 31) for input Tensor(\"input_A_3:0\", shape=(None, 20, 31), dtype=float32), but it was called on an input with incompatible shape (None, 10, 31).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20, 31) for input Tensor(\"input_A_3:0\", shape=(None, 20, 31), dtype=float32), but it was called on an input with incompatible shape (None, 10, 31).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20, 31) for input Tensor(\"input_A_2:0\", shape=(None, 20, 31), dtype=float32), but it was called on an input with incompatible shape (None, 10, 31).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20, 31) for input Tensor(\"input_A_2:0\", shape=(None, 20, 31), dtype=float32), but it was called on an input with incompatible shape (None, 10, 31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_0_1 - loss:  1.2399794287383556\n",
      "model_0_1 - loss:  0.908804241642356\n",
      "model_0_1 - loss:  0.7335450089424849\n",
      "model_0_1 - loss:  0.6347356769964099\n",
      "model_0_1 - loss:  0.5332564210146665\n",
      "model_0_1 - loss:  0.4699535935819149\n",
      "model_0_1 - loss:  0.4303412746265531\n",
      "model_0_1 - loss:  0.3846493941731751\n",
      "model_0_1 - loss:  0.35753752798214555\n",
      "model_0_1 - loss:  0.33314108207076787\n",
      "model_0_1 - loss:  0.3209772971253842\n",
      "model_0_1 - loss:  0.30028758631832897\n",
      "model_0_1 - loss:  0.2803442635498941\n",
      "model_0_1 - loss:  0.2798271372690797\n",
      "model_0_1 - loss:  0.2668539771009237\n",
      "model_0_1 - loss:  0.2571242012307048\n",
      "model_0_1 - loss:  0.25172699352540073\n",
      "model_0_1 - loss:  0.2361077525569126\n",
      "model_0_1 - loss:  0.23251615720894186\n",
      "model_0_1 - loss:  0.2335380830867216\n",
      "model_0_1 - loss:  0.2131701999446377\n",
      "model_0_1 - loss:  0.21509645228274166\n",
      "model_0_1 - loss:  0.21176635797787458\n",
      "model_0_1 - loss:  0.20634426823165267\n",
      "model_0_1 - loss:  0.19984655385278166\n",
      "model_0_1 - loss:  0.20739763625897467\n",
      "model_0_1 - loss:  0.17975817758310586\n",
      "model_0_1 - loss:  0.1976953515233472\n",
      "model_0_1 - loss:  0.17715956978313624\n",
      "model_0_1 - loss:  0.18876431566663088\n",
      "model_0_1 - loss:  0.17984215502999723\n",
      "model_0_1 - loss:  0.1757897811094299\n",
      "model_0_1 - loss:  0.17827335759392007\n",
      "model_0_1 - loss:  0.1638582951873541\n",
      "model_0_1 - loss:  0.16025730211567132\n",
      "model_0_1 - loss:  0.16786163206212223\n",
      "model_0_1 - loss:  0.1657520820009522\n",
      "model_0_1 - loss:  0.15856402792222798\n",
      "model_0_1 - loss:  0.1579540115520358\n",
      "model_0_1 - loss:  0.15630913702771068\n",
      "model_0_1 - loss:  0.14914106727438048\n",
      "model_0_1 - loss:  0.14738547965371981\n",
      "model_0_1 - loss:  0.1518100969721563\n",
      "model_0_1 - loss:  0.15196604340989142\n",
      "model_0_1 - loss:  0.14183819401310757\n",
      "model_0_1 - loss:  0.14698030869569628\n",
      "model_0_1 - loss:  0.14774433706887066\n",
      "model_0_1 - loss:  0.1318438180182129\n",
      "model_0_1 - loss:  0.1347719177841209\n",
      "model_0_1 - loss:  0.14135443543363363\n",
      "model_0_1 - loss:  0.129040062231943\n",
      "model_0_1 - loss:  0.13473928874824195\n",
      "model_0_1 - loss:  0.1381412956472486\n",
      "model_0_1 - loss:  0.13633738350635394\n",
      "model_0_1 - loss:  0.1291335618752055\n",
      "model_0_1 - loss:  0.13058949428144842\n",
      "model_0_1 - loss:  0.13005995482578875\n",
      "model_0_1 - loss:  0.12038450605655089\n",
      "model_0_1 - loss:  0.12333405005186796\n",
      "model_0_1 - loss:  0.11719190226960927\n",
      "model_0_1 - loss:  0.11973673484986648\n",
      "model_0_1 - loss:  0.12851490781735628\n",
      "model_0_1 - loss:  0.1181152911358513\n",
      "model_0_1 - loss:  0.1179724808386527\n",
      "model_0_1 - loss:  0.1222839113934897\n",
      "model_0_1 - loss:  0.11875954382494092\n",
      "model_0_1 - loss:  0.12389322545938194\n",
      "model_0_1 - loss:  0.11464549501333386\n",
      "model_0_1 - loss:  0.10801250391500071\n",
      "model_0_1 - loss:  0.12616561351716518\n",
      "model_0_1 - loss:  0.101990070912987\n",
      "model_0_1 - loss:  0.11343290752987377\n",
      "model_0_1 - loss:  0.10366026999172755\n",
      "model_0_1 - loss:  0.11089808214851656\n",
      "model_0_1 - loss:  0.11015557543747127\n",
      "model_0_1 - loss:  0.11795485006691887\n",
      "model_0_1 - loss:  0.10114303969661705\n",
      "model_0_1 - loss:  0.1027334877194371\n",
      "model_0_1 - loss:  0.10812293154606596\n",
      "model_0_1 - loss:  0.11529296353086829\n",
      "model_0_1 - loss:  0.09851795867248438\n",
      "model_0_1 - loss:  0.09699300022469834\n",
      "model_0_1 - loss:  0.10324234239012003\n",
      "model_0_1 - loss:  0.10172650982299819\n",
      "model_0_1 - loss:  0.10009412568039261\n",
      "model_0_1 - loss:  0.10626319863041862\n"
     ]
    }
   ],
   "source": [
    "# version 1\n",
    "# adapt my mind to the observation\n",
    "# no action applied\n",
    "\n",
    "step = 15\n",
    "training_times = 3;\n",
    "counter = 0;\n",
    "loss_0_1_ = 0\n",
    "\n",
    "for n in range(1,step+1):\n",
    "    for times in range(training_times):\n",
    "        for window in shuffle_dataset: #(18,10,31)\n",
    "            initial = window\n",
    "\n",
    "            for i in range(n): # n step forward\n",
    "                counter = counter + 1\n",
    "\n",
    "                #output_A_0_1_ = sub_model_0_1_.predict(initial) #(18,30)\n",
    "                #out_0_1_0 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                #for i in range(batch_size):\n",
    "                #    # pred_A_class_random_0_1_ = np.random.choice(30, 1, p=output_A_0_1_[i,:])[0]\n",
    "                #    pred_A_class_max_0_1_ = np.where(output_A_0_1_[i,:] == np.max(output_A_0_1_[i,:]))[0][0]\n",
    "#\n",
    "                #    # one_hot = tf.reshape(tf.one_hot(pred_A_class_random_0_1_, 30),[1,1,30])\n",
    "                #    one_hot = tf.reshape(tf.one_hot(pred_A_class_max_0_1_, 30),[1,1,30])\n",
    "#\n",
    "                #    out_0_1_0[i:i+1,:,:] = np.concatenate((one_hot,[[[0]]]),2) #(18,1,31)\n",
    "\n",
    "                #output_RNN, y_pred_A_0_1_, y_pred_B_0_1_ = model_0_1_.predict((initial,out_0_1_0))\n",
    "                #y_pred_B_0_1_  #(18,30)\n",
    "                #out_0_1_1 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                #for i in range(batch_size):\n",
    "                    # pred_B_class_random_0_1_ = np.random.choice(30, 1, p=y_pred_B_0_1_[i,:])[0]\n",
    "                 #   pred_B_class_max_0_1_ = np.where(y_pred_B_0_1_[i,:] == np.max(y_pred_B_0_1_[i,:]))[0][0]\n",
    "\n",
    "                    # one_hot = tf.reshape(tf.one_hot(pred_B_class_random_0_1_, 30),[1,1,30])\n",
    "                 #   one_hot = tf.reshape(tf.one_hot(pred_B_class_max_0_1_, 30),[1,1,30])\n",
    "\n",
    "                 #   out_0_1_1[i:i+1,:,:]= np.concatenate((one_hot,[[[1]]]),2) #(18,1,31)\n",
    "\n",
    "                output_A_1_0_ = sub_model_1_0_.predict(initial) #(18,30)\n",
    "                out_1_0_1 =  tf.reshape(output_A_1_0_,[batch_size,1,30]) #(18,1,30)\n",
    "\n",
    "                one = tf.reshape(tf.ones(batch_size),[batch_size,1,1])\n",
    "                out_1_0_1 =  np.concatenate((out_1_0_1,one),2) #(18,1,31)\n",
    "                    \n",
    "                #out_1_0_1 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                #for i in range(batch_size):\n",
    "                    # pred_A_class_random_1_0_ = np.random.choice(30, 1, p=output_A_1_0_[i,:])[0]\n",
    "                 #   pred_A_class_max_1_0_ = np.where(output_A_1_0_[i,:] == np.max(output_A_1_0_[i,:]))[0][0]\n",
    "\n",
    "                    # one_hot = tf.reshape(tf.one_hot(pred_A_class_random_1_0_, 30),[1,1,30])\n",
    "                 #   one_hot = tf.reshape(tf.one_hot(pred_A_class_max_1_0_, 30),[1,1,30])\n",
    "\n",
    "                 #   out_1_0_1[i:i+1,:,:] = np.concatenate((one_hot,[[[1]]]),2) #(18,1,31)\n",
    "\n",
    "                output_RNN, y_pred_A_1_0_, y_pred_B_1_0_ = model_1_0_.predict((initial,out_1_0_1))\n",
    "                y_pred_B_1_0_  #(18,30)\n",
    "                out_1_0_0 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                for i in range(batch_size):\n",
    "                    # pred_B_class_random_1_0_ = np.random.choice(30, 1, p=y_pred_B_1_0_[i,:])[0]\n",
    "                    pred_B_class_max_1_0_ = np.where(y_pred_B_1_0_[i,:] == np.max(y_pred_B_1_0_[i,:]))[0][0]\n",
    "\n",
    "                    # one_hot = tf.reshape(tf.one_hot(pred_B_class_random_1_0_, 30),[1,1,30])\n",
    "                    one_hot = tf.reshape(tf.one_hot(pred_B_class_max_1_0_, 30),[1,1,30])\n",
    "\n",
    "                    out_1_0_0[i:i+1,:,:]= np.concatenate((one_hot,[[[0]]]),2) #(18,1,31)\n",
    "\n",
    "\n",
    "                #target_0_1_0 = np.reshape(out_0_1_0,[batch_size,31])[:,:-1]\n",
    "                #target_0_1_1 = np.reshape(out_0_1_1,[batch_size,31])[:,:-1]\n",
    "                #target_1_0_1 = np.reshape(out_1_0_1,[batch_size,31])[:,:-1]\n",
    "                target_1_0_0 = np.reshape(out_1_0_0,[batch_size,31])[:,:-1]\n",
    "\n",
    "                History_0_1_ = sub_model_0_1_.fit(initial,target_1_0_0,verbose = 0)\n",
    "                loss_0_1_ = loss_0_1_ + History_0_1_.history.get('loss')[0]\n",
    "                \n",
    "                if counter%2000 == 0:\n",
    "                    print('model_0_1 - loss: ', loss_0_1_/2000)\n",
    "                    loss_0_1_ = 0\n",
    "                    \n",
    "                initial = tf.concat((initial[:,:-1,:],out_1_0_0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2\n",
    "# adapt my mind to the observation\n",
    "# apply my assumed action to the environment\n",
    "# sequential\n",
    "\n",
    "step = 15\n",
    "training_times = 3;\n",
    "counter = 0;\n",
    "loss_0_1_ = 0\n",
    "\n",
    "for n in range(1,step+1):\n",
    "    for times in range(training_times):\n",
    "        for window in shuffle_dataset: #(18,10,31)\n",
    "            initial = window\n",
    "            \n",
    "            for i in range(n): # n step forward\n",
    "                counter = counter + 1\n",
    "\n",
    "                output_A_0_1_ = sub_model_0_1_.predict(initial) #(18,30)\n",
    "                \n",
    "                out_0_1_0 =  tf.reshape(output_A_0_1_,[batch_size,1,30]) #(18,1,30)\n",
    "                one = tf.reshape(tf.ones(batch_size),[batch_size,1,1])\n",
    "                out_0_1_0 =  np.concatenate((out_0_1_0,one),2) #(18,1,31)\n",
    "                \n",
    "                \n",
    "                \n",
    "                #out_0_1_0 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                #for i in range(batch_size):\n",
    "                #    # pred_A_class_random_0_1_ = np.random.choice(30, 1, p=output_A_0_1_[i,:])[0]\n",
    "                #    pred_A_class_max_0_1_ = np.where(output_A_0_1_[i,:] == np.max(output_A_0_1_[i,:]))[0][0]\n",
    "#\n",
    "                #    # one_hot = tf.reshape(tf.one_hot(pred_A_class_random_0_1_, 30),[1,1,30])\n",
    "                #    one_hot = tf.reshape(tf.one_hot(pred_A_class_max_0_1_, 30),[1,1,30])\n",
    "#\n",
    "                #    out_0_1_0[i:i+1,:,:] = np.concatenate((one_hot,[[[0]]]),2) #(18,1,31)\n",
    "\n",
    "                output_RNN, y_pred_A_0_1_, y_pred_B_0_1_ = model_0_1_.predict((initial,out_0_1_0))\n",
    "                y_pred_B_0_1_  #(18,30)\n",
    "                out_0_1_1 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                for i in range(batch_size):\n",
    "                    # pred_B_class_random_0_1_ = np.random.choice(30, 1, p=y_pred_B_0_1_[i,:])[0]\n",
    "                    pred_B_class_max_0_1_ = np.where(y_pred_B_0_1_[i,:] == np.max(y_pred_B_0_1_[i,:]))[0][0]\n",
    "\n",
    "                    # one_hot = tf.reshape(tf.one_hot(pred_B_class_random_0_1_, 30),[1,1,30])\n",
    "                    one_hot = tf.reshape(tf.one_hot(pred_B_class_max_0_1_, 30),[1,1,30])\n",
    "\n",
    "                    out_0_1_1[i:i+1,:,:]= np.concatenate((one_hot,[[[1]]]),2) #(18,1,31)\n",
    "\n",
    "                #output_A_1_0_ = sub_model_1_0_.predict(initial) #(18,30)\n",
    "                #out_1_0_1 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                #for i in range(batch_size):\n",
    "                #    # pred_A_class_random_1_0_ = np.random.choice(30, 1, p=output_A_1_0_[i,:])[0]\n",
    "                #    pred_A_class_max_1_0_ = np.where(output_A_1_0_[i,:] == np.max(output_A_1_0_[i,:]))[0][0]\n",
    "#\n",
    "                #    # one_hot = tf.reshape(tf.one_hot(pred_A_class_random_1_0_, 30),[1,1,30])\n",
    "                #    one_hot = tf.reshape(tf.one_hot(pred_A_class_max_1_0_, 30),[1,1,30])\n",
    "#\n",
    "                #    out_1_0_1[i:i+1,:,:] = np.concatenate((one_hot,[[[1]]]),2) #(18,1,31)\n",
    "#\n",
    "                output_RNN, y_pred_A_1_0_, y_pred_B_1_0_ = model_1_0_.predict((initial,out_0_1_1))\n",
    "                y_pred_B_1_0_  #(18,30)\n",
    "                out_1_0_0 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                for i in range(batch_size):\n",
    "                    # pred_B_class_random_1_0_ = np.random.choice(30, 1, p=y_pred_B_1_0_[i,:])[0]\n",
    "                    pred_B_class_max_1_0_ = np.where(y_pred_B_1_0_[i,:] == np.max(y_pred_B_1_0_[i,:]))[0][0]\n",
    "\n",
    "                    # one_hot = tf.reshape(tf.one_hot(pred_B_class_random_1_0_, 30),[1,1,30])\n",
    "                    one_hot = tf.reshape(tf.one_hot(pred_B_class_max_1_0_, 30),[1,1,30])\n",
    "\n",
    "                    out_1_0_0[i:i+1,:,:]= np.concatenate((one_hot,[[[0]]]),2) #(18,1,31)\n",
    "\n",
    "                #target_0_1_0 = np.reshape(out_0_1_0,[batch_size,31])[:,:-1]\n",
    "                #target_0_1_1 = np.reshape(out_0_1_1,[batch_size,31])[:,:-1]\n",
    "                #target_1_0_1 = np.reshape(out_1_0_1,[batch_size,31])[:,:-1]\n",
    "                target_1_0_0 = np.reshape(out_1_0_0,[batch_size,31])[:,:-1]\n",
    "\n",
    "                \n",
    "                History_0_1_ = sub_model_0_1_.fit(initial,target_1_0_0,verbose = 0)\n",
    "                loss_0_1_ = loss_0_1_ + History_0_1_.history.get('loss')[0]\n",
    "                \n",
    "                if counter%2000 == 0:\n",
    "                    print('model_0_1 - loss: ', loss_0_1_/2000)\n",
    "                    loss_0_1_ = 0\n",
    "                   \n",
    "                initial = tf.concat((initial[:,:-1,:],out_1_0_0),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3\n",
    "# actively choose my action for desired results\n",
    "# experiment on the environment without cost\n",
    "# maximum likelihood collapse (could be modified to KL divergence)\n",
    "\n",
    "step = 15\n",
    "training_times = 3;\n",
    "counter = 0;\n",
    "loss_0_1_ = 0\n",
    "\n",
    "for n in range(1,step+1):\n",
    "    for times in range(training_times):\n",
    "        for window in shuffle_dataset: #(18,10,31)\n",
    "            initial = window\n",
    "            \n",
    "            for i in range(n): # n step forward\n",
    "                counter = counter + 1\n",
    "\n",
    "                output_A_0_1_ = sub_model_0_1_.predict(initial) #(18,30) # my prediction about observation\n",
    "                \n",
    "                out_0_1_0 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                    for i in range(batch_size):\n",
    "                        # pred_A_class_random_0_1_ = np.random.choice(30, 1, p=output_A_0_1_[i,:])[0]\n",
    "                        pred_A_class_max_0_1_ = np.where(output_A_0_1_[i,:] == np.max(output_A_0_1_[i,:]))[0][0]\n",
    "                        \n",
    "                        # one_hot = tf.reshape(tf.one_hot(pred_A_class_random_0_1_, 30),[1,1,30])\n",
    "                        one_hot = tf.reshape(tf.one_hot(pred_A_class_max_0_1_, 30),[1,1,30])\n",
    "                        \n",
    "                        out_0_1_0[i:i+1,:,:] = np.concatenate((one_hot,[[[0]]]),2) #(18,1,31)\n",
    "                        \n",
    "                target_0_1_0 = np.reshape(out_0_1_0,[batch_size,31])[:,:-1]\n",
    "                \n",
    "                target_0_1_1 = np.zeros((batch_size,30))\n",
    "                for i in range(batch_size):\n",
    "                    prob = np.zeros((30,))\n",
    "                    for j in range(30):\n",
    "                        one_hot = tf.reshape(tf.one_hot(j, 30),[1,1,30])\n",
    "                        out_0_1_1 = np.concatenate((one_hot,[[[1]]]),2) #(1,1,31) # my action\n",
    "                        \n",
    "                        output_RNN, y_pred_A_1_0_, y_pred_B_1_0_ = model_1_0_.predict((initial,out_0_1_1)) # my action on environment\n",
    "                        y_pred_B_1_0_  #(1,30) # observation\n",
    "                        prob[j] = y_pred_B_1_0_[0,pred_A_class_max_0_1_] # probability on desired observation\n",
    "                        \n",
    "                    the_j = np.where(prob == np.max(prob))[0][0]\n",
    "                    one_hot = tf.reshape(tf.one_hot(the_j, 30),[1,30])\n",
    "                    target_0_1_1[i,:] = one_hot #(18,30) # desired action\n",
    "\n",
    "                \n",
    "                History_0_1_ = aux_model_0_1_.fit([initial,out_0_1_0],[target_0_1_0,target_0_1_1],verbose = 0)\n",
    "                loss_0_1_ = loss_0_1_ + History_0_1_.history.get('loss')[0]\n",
    "                \n",
    "                if counter%2000 == 0:\n",
    "                    print('model_0_1 - loss: ', loss_0_1_/2000)\n",
    "                    loss_0_1_ = 0\n",
    "                   \n",
    "                initial = tf.concat((initial[:,:-1,:],out_0_1_0),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4\n",
    "# actively choose my action for desired results\n",
    "# cannot experiment on the environment; choose action by probability guessing\n",
    "\n",
    "step = 15\n",
    "training_times = 3;\n",
    "counter = 0;\n",
    "loss_0_1_ = 0\n",
    "\n",
    "for n in range(1,step+1):\n",
    "    for times in range(training_times):\n",
    "        for window in shuffle_dataset: #(18,10,31)\n",
    "            initial = window\n",
    "            \n",
    "            for i in range(n): # n step forward\n",
    "                counter = counter + 1\n",
    "\n",
    "                output_A_0_1_ = sub_model_0_1_.predict(initial) #(18,30)\n",
    "                \n",
    "                out_0_1_0 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                    for i in range(batch_size):\n",
    "                        # pred_A_class_random_0_1_ = np.random.choice(30, 1, p=output_A_0_1_[i,:])[0]\n",
    "                        pred_A_class_max_0_1_ = np.where(output_A_0_1_[i,:] == np.max(output_A_0_1_[i,:]))[0][0]\n",
    "                        \n",
    "                        # one_hot = tf.reshape(tf.one_hot(pred_A_class_random_0_1_, 30),[1,1,30])\n",
    "                        one_hot = tf.reshape(tf.one_hot(pred_A_class_max_0_1_, 30),[1,1,30])\n",
    "                        \n",
    "                        out_0_1_0[i:i+1,:,:] = np.concatenate((one_hot,[[[0]]]),2) #(18,1,31)\n",
    "                        \n",
    "                \n",
    "                output_RNN, y_pred_A_0_1_, y_pred_B_0_1_ = model_0_1_.predict((initial,out_0_1_0))\n",
    "                y_pred_B_0_1_  #(18,30)\n",
    "                out_0_1_1 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                for i in range(batch_size):\n",
    "                    # pred_B_class_random_0_1_ = np.random.choice(30, 1, p=y_pred_B_0_1_[i,:])[0]\n",
    "                    pred_B_class_max_0_1_ = np.where(y_pred_B_0_1_[i,:] == np.max(y_pred_B_0_1_[i,:]))[0][0]\n",
    "\n",
    "                    # one_hot = tf.reshape(tf.one_hot(pred_B_class_random_0_1_, 30),[1,1,30])\n",
    "                    one_hot = tf.reshape(tf.one_hot(pred_B_class_max_0_1_, 30),[1,1,30])\n",
    "\n",
    "                    out_0_1_1[i:i+1,:,:]= np.concatenate((one_hot,[[[1]]]),2) #(18,1,31)\n",
    "\n",
    "                #output_A_1_0_ = sub_model_1_0_.predict(initial) #(18,30)\n",
    "                #out_1_0_1 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                #for i in range(batch_size):\n",
    "                #    # pred_A_class_random_1_0_ = np.random.choice(30, 1, p=output_A_1_0_[i,:])[0]\n",
    "                #    pred_A_class_max_1_0_ = np.where(output_A_1_0_[i,:] == np.max(output_A_1_0_[i,:]))[0][0]\n",
    "#\n",
    "                #    # one_hot = tf.reshape(tf.one_hot(pred_A_class_random_1_0_, 30),[1,1,30])\n",
    "                #    one_hot = tf.reshape(tf.one_hot(pred_A_class_max_1_0_, 30),[1,1,30])\n",
    "#\n",
    "                #    out_1_0_1[i:i+1,:,:] = np.concatenate((one_hot,[[[1]]]),2) #(18,1,31)\n",
    "#\n",
    "                output_RNN, y_pred_A_1_0_, y_pred_B_1_0_ = model_1_0_.predict((initial,out_0_1_1))\n",
    "                y_pred_B_1_0_  #(18,30)\n",
    "                out_1_0_0 = np.zeros([batch_size,1,31]) #(18,1,31)\n",
    "                for i in range(batch_size):\n",
    "                    # pred_B_class_random_1_0_ = np.random.choice(30, 1, p=y_pred_B_1_0_[i,:])[0]\n",
    "                    pred_B_class_max_1_0_ = np.where(y_pred_B_1_0_[i,:] == np.max(y_pred_B_1_0_[i,:]))[0][0]\n",
    "\n",
    "                    # one_hot = tf.reshape(tf.one_hot(pred_B_class_random_1_0_, 30),[1,1,30])\n",
    "                    one_hot = tf.reshape(tf.one_hot(pred_B_class_max_1_0_, 30),[1,1,30])\n",
    "\n",
    "                    out_1_0_0[i:i+1,:,:]= np.concatenate((one_hot,[[[0]]]),2) #(18,1,31)\n",
    "\n",
    "                #target_0_1_0 = np.reshape(out_0_1_0,[batch_size,31])[:,:-1]\n",
    "                #target_0_1_1 = np.reshape(out_0_1_1,[batch_size,31])[:,:-1]\n",
    "                #target_1_0_1 = np.reshape(out_1_0_1,[batch_size,31])[:,:-1]\n",
    "                target_1_0_0 = np.reshape(out_1_0_0,[batch_size,31])[:,:-1]\n",
    "\n",
    "                \n",
    "                History_0_1_ = aux_model_0_1_.fit([initial,out_0_1_0],[target_0_1_0,target_0_1_1],verbose = 0)\n",
    "                loss_0_1_ = loss_0_1_ + History_0_1_.history.get('loss')[0]\n",
    "                \n",
    "                if counter%2000 == 0:\n",
    "                    print('model_0_1 - loss: ', loss_0_1_/2000)\n",
    "                    loss_0_1_ = 0\n",
    "                   \n",
    "                initial = tf.concat((initial[:,:-1,:],out_0_1_0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_1_.save_weights('version1_mindAdapt_withoutAction_model_0_1_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
