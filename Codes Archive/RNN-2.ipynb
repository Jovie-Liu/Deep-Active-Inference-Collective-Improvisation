{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:pynput was not found; mouse and keyboard input will not be available.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scamp import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Flatten,Softmax,Input\n",
    "import keras.backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cantus  Counter\n",
      "0         58       67\n",
      "1         66       69\n",
      "2         64       71\n",
      "3         68       76\n",
      "4         66       74\n",
      "...      ...      ...\n",
      "9995      64       72\n",
      "9996      56       60\n",
      "9997      57       61\n",
      "9998      61       65\n",
      "9999      56       64\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Species.csv', sep=\",\",index_col = 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = df.shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 20000) dtype=int32, numpy=\n",
       "array([[15, 12, 23, ..., 10, 13,  9],\n",
       "       [ 0,  1,  0, ...,  1,  0,  1]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.Variable(np.zeros((2,n*2)),dtype='int32')  # any data tensor\n",
    "for i in range(0,2*n,2):\n",
    "    X[0,i].assign(df['Cantus'][i/2] - 43)\n",
    "    X[1,i].assign(0)\n",
    "    X[0,i+1].assign(df['Counter'][i/2] - 55)\n",
    "    X[1,i+1].assign(1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20000, 31), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 30\n",
    "X = tf.concat([tf.one_hot(X[0,:], depth),tf.dtypes.cast(tf.reshape(X[1,:],[20000,1]),tf.float32)],1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(X[:7000,:])\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(X[7000:9000,:])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(X[9000:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset,batch_size):\n",
    "    n_steps = 20\n",
    "    window_length = n_steps + 2 # target = input shifted 1 character ahead\n",
    "    dataset = dataset.window(window_length, shift=2, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    \n",
    "    shuffle_dataset = dataset.shuffle(7000).batch(batch_size)\n",
    "    map_dataset = shuffle_dataset.map(lambda windows: (windows[:,:-2,:], windows[:,-2:-1,:],windows[:,-2,:],windows[:,-1,:]))\n",
    "    final_dataset = map_dataset.map(\n",
    "        lambda X_batch, Y_batch, Z_batch, U_batch: ((X_batch, Y_batch), (Z_batch[:,:-1], U_batch[:,:-1])))\n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B1E53A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B1E53A8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B1E5558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B1E5558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B242318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B242318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B2421F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B2421F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B242F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B242F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B301168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function data_process.<locals>.<lambda> at 0x000001D60B301168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "train = data_process(train_dataset,batch_size)\n",
    "valid = data_process(valid_dataset,batch_size)\n",
    "test = data_process(test_dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_units = 12\n",
    "n_notes = 30\n",
    "\n",
    "input_A = keras.layers.Input(shape=(20,31), name=\"input_A\") # (15, 20, 31)\n",
    "input_B = keras.layers.Input(shape=(1,31), name=\"input_B\") # (15, 1, 31)\n",
    "\n",
    "hidden1 = keras.layers.LSTM(rnn_units, return_sequences=True)(input_A) # (15,20,12)\n",
    "hidden2 = keras.layers.LSTM(rnn_units, return_sequences=True)(hidden1) #(15,20,12)\n",
    "\n",
    "output_RNN = keras.layers.Dense(n_notes, activation='softmax')(hidden2) #(15,20,30)\n",
    "\n",
    "\n",
    "e = keras.layers.Dense(1, activation='tanh')(hidden2) #(15,20,1)\n",
    "e = keras.layers.Reshape([-1])(e) #(15,20)\n",
    "\n",
    "alpha = keras.layers.Activation('softmax')(e) #(15,20)\n",
    "c = keras.layers.Permute([2, 1])(keras.layers.RepeatVector(rnn_units)(alpha)) #(15,20,12)\n",
    "c = keras.layers.Multiply()([hidden2, c]) #(15,20,12)\n",
    "c = keras.layers.Lambda(lambda xin: K.sum(xin, axis=1), output_shape=(rnn_units,))(c) #(15,12)\n",
    "\n",
    "output_A = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_A')(c) #(15,30) (0, cantus)\n",
    "\n",
    "aux = keras.layers.SimpleRNN(rnn_units)(input_B, initial_state=c) #(15,12)\n",
    "output_B = keras.layers.Dense(n_notes, activation = 'softmax', name = 'output_B')(aux) #(15,30) (1, counter)\n",
    "\n",
    "model = keras.models.Model([input_A, input_B], [output_RNN, output_A, output_B])\n",
    "att_model = keras.models.Model([input_A, input_B], alpha)\n",
    "sub_model = keras.models.Model(input_A, output_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_A (InputLayer)            [(None, 20, 31)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 20, 12)       2112        input_A[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 20, 12)       1200        lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 20, 1)        13          lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 20)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 20)           0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 12, 20)       0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 20, 12)       0           repeat_vector_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 20, 12)       0           lstm_7[0][0]                     \n",
      "                                                                 permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 12)           0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_B (InputLayer)            [(None, 1, 31)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)        (None, 12)           528         input_B[0][0]                    \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_A (Dense)                (None, 30)           390         lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_B (Dense)                (None, 30)           390         simple_rnn_3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,633\n",
      "Trainable params: 4,633\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy','categorical_crossentropy'],\n",
    "              optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "175/175 [==============================] - 3s 18ms/step - loss: 5.9450 - output_A_loss: 3.2311 - output_B_loss: 2.7139 - val_loss: 6.0012 - val_output_A_loss: 3.2654 - val_output_B_loss: 2.7358\n",
      "Epoch 2/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.9199 - output_A_loss: 3.2305 - output_B_loss: 2.6894 - val_loss: 5.9769 - val_output_A_loss: 3.2650 - val_output_B_loss: 2.7119\n",
      "Epoch 3/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.8945 - output_A_loss: 3.2297 - output_B_loss: 2.6648 - val_loss: 5.9524 - val_output_A_loss: 3.2643 - val_output_B_loss: 2.6881\n",
      "Epoch 4/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.8695 - output_A_loss: 3.2291 - output_B_loss: 2.6403 - val_loss: 5.9278 - val_output_A_loss: 3.2638 - val_output_B_loss: 2.6640\n",
      "Epoch 5/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.8443 - output_A_loss: 3.2284 - output_B_loss: 2.6159 - val_loss: 5.9036 - val_output_A_loss: 3.2633 - val_output_B_loss: 2.6402\n",
      "Epoch 6/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.8193 - output_A_loss: 3.2277 - output_B_loss: 2.5916 - val_loss: 5.8793 - val_output_A_loss: 3.2628 - val_output_B_loss: 2.6165\n",
      "Epoch 7/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.7945 - output_A_loss: 3.2269 - output_B_loss: 2.5676 - val_loss: 5.8538 - val_output_A_loss: 3.2617 - val_output_B_loss: 2.5921\n",
      "Epoch 8/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.7698 - output_A_loss: 3.2261 - output_B_loss: 2.5437 - val_loss: 5.8308 - val_output_A_loss: 3.2611 - val_output_B_loss: 2.5697\n",
      "Epoch 9/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.7453 - output_A_loss: 3.2249 - output_B_loss: 2.5204 - val_loss: 5.8059 - val_output_A_loss: 3.2596 - val_output_B_loss: 2.5462\n",
      "Epoch 10/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.7214 - output_A_loss: 3.2238 - output_B_loss: 2.4976 - val_loss: 5.7822 - val_output_A_loss: 3.2589 - val_output_B_loss: 2.5233\n",
      "Epoch 11/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.6980 - output_A_loss: 3.2227 - output_B_loss: 2.4752 - val_loss: 5.7629 - val_output_A_loss: 3.2586 - val_output_B_loss: 2.5043\n",
      "Epoch 12/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.6757 - output_A_loss: 3.2216 - output_B_loss: 2.4541 - val_loss: 5.7396 - val_output_A_loss: 3.2572 - val_output_B_loss: 2.4824\n",
      "Epoch 13/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.6538 - output_A_loss: 3.2200 - output_B_loss: 2.4338 - val_loss: 5.7142 - val_output_A_loss: 3.2543 - val_output_B_loss: 2.4599\n",
      "Epoch 14/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.6327 - output_A_loss: 3.2186 - output_B_loss: 2.4141 - val_loss: 5.6949 - val_output_A_loss: 3.2536 - val_output_B_loss: 2.4413\n",
      "Epoch 15/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.6125 - output_A_loss: 3.2171 - output_B_loss: 2.3954 - val_loss: 5.6747 - val_output_A_loss: 3.2521 - val_output_B_loss: 2.4226\n",
      "Epoch 16/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.5928 - output_A_loss: 3.2155 - output_B_loss: 2.3774 - val_loss: 5.6556 - val_output_A_loss: 3.2502 - val_output_B_loss: 2.4055\n",
      "Epoch 17/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.5743 - output_A_loss: 3.2137 - output_B_loss: 2.3606 - val_loss: 5.6350 - val_output_A_loss: 3.2474 - val_output_B_loss: 2.3876\n",
      "Epoch 18/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.5559 - output_A_loss: 3.2121 - output_B_loss: 2.3437 - val_loss: 5.6197 - val_output_A_loss: 3.2470 - val_output_B_loss: 2.3727\n",
      "Epoch 19/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.5382 - output_A_loss: 3.2106 - output_B_loss: 2.3277 - val_loss: 5.6007 - val_output_A_loss: 3.2446 - val_output_B_loss: 2.3561\n",
      "Epoch 20/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.5207 - output_A_loss: 3.2087 - output_B_loss: 2.3120 - val_loss: 5.5857 - val_output_A_loss: 3.2437 - val_output_B_loss: 2.3420\n",
      "Epoch 21/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.5038 - output_A_loss: 3.2068 - output_B_loss: 2.2970 - val_loss: 5.5688 - val_output_A_loss: 3.2415 - val_output_B_loss: 2.3273\n",
      "Epoch 22/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.4873 - output_A_loss: 3.2046 - output_B_loss: 2.2827 - val_loss: 5.5511 - val_output_A_loss: 3.2384 - val_output_B_loss: 2.3126\n",
      "Epoch 23/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.4710 - output_A_loss: 3.2026 - output_B_loss: 2.2685 - val_loss: 5.5344 - val_output_A_loss: 3.2354 - val_output_B_loss: 2.2990\n",
      "Epoch 24/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.4552 - output_A_loss: 3.2004 - output_B_loss: 2.2548 - val_loss: 5.5241 - val_output_A_loss: 3.2355 - val_output_B_loss: 2.2886\n",
      "Epoch 25/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.4402 - output_A_loss: 3.1980 - output_B_loss: 2.2421 - val_loss: 5.5058 - val_output_A_loss: 3.2316 - val_output_B_loss: 2.2741\n",
      "Epoch 26/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.4250 - output_A_loss: 3.1957 - output_B_loss: 2.2293 - val_loss: 5.4915 - val_output_A_loss: 3.2297 - val_output_B_loss: 2.2618\n",
      "Epoch 27/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.4103 - output_A_loss: 3.1928 - output_B_loss: 2.2175 - val_loss: 5.4773 - val_output_A_loss: 3.2268 - val_output_B_loss: 2.2505\n",
      "Epoch 28/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.3960 - output_A_loss: 3.1904 - output_B_loss: 2.2056 - val_loss: 5.4615 - val_output_A_loss: 3.2226 - val_output_B_loss: 2.2389\n",
      "Epoch 29/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.3819 - output_A_loss: 3.1872 - output_B_loss: 2.1947 - val_loss: 5.4481 - val_output_A_loss: 3.2196 - val_output_B_loss: 2.2285\n",
      "Epoch 30/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.3679 - output_A_loss: 3.1840 - output_B_loss: 2.1839 - val_loss: 5.4341 - val_output_A_loss: 3.2161 - val_output_B_loss: 2.2180\n",
      "Epoch 31/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.3538 - output_A_loss: 3.1807 - output_B_loss: 2.1732 - val_loss: 5.4191 - val_output_A_loss: 3.2123 - val_output_B_loss: 2.2068\n",
      "Epoch 32/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.3403 - output_A_loss: 3.1770 - output_B_loss: 2.1633 - val_loss: 5.4101 - val_output_A_loss: 3.2114 - val_output_B_loss: 2.1987\n",
      "Epoch 33/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.3269 - output_A_loss: 3.1737 - output_B_loss: 2.1532 - val_loss: 5.3941 - val_output_A_loss: 3.2058 - val_output_B_loss: 2.1883\n",
      "Epoch 34/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.3135 - output_A_loss: 3.1698 - output_B_loss: 2.1437 - val_loss: 5.3786 - val_output_A_loss: 3.2005 - val_output_B_loss: 2.1781\n",
      "Epoch 35/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.3002 - output_A_loss: 3.1653 - output_B_loss: 2.1349 - val_loss: 5.3692 - val_output_A_loss: 3.1989 - val_output_B_loss: 2.1704\n",
      "Epoch 36/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.2871 - output_A_loss: 3.1616 - output_B_loss: 2.1255 - val_loss: 5.3531 - val_output_A_loss: 3.1913 - val_output_B_loss: 2.1618\n",
      "Epoch 37/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.2740 - output_A_loss: 3.1568 - output_B_loss: 2.1172 - val_loss: 5.3448 - val_output_A_loss: 3.1902 - val_output_B_loss: 2.1545\n",
      "Epoch 38/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.2610 - output_A_loss: 3.1521 - output_B_loss: 2.1089 - val_loss: 5.3292 - val_output_A_loss: 3.1843 - val_output_B_loss: 2.1449\n",
      "Epoch 39/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.2473 - output_A_loss: 3.1475 - output_B_loss: 2.0999 - val_loss: 5.3151 - val_output_A_loss: 3.1758 - val_output_B_loss: 2.1393\n",
      "Epoch 40/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.2348 - output_A_loss: 3.1428 - output_B_loss: 2.0920 - val_loss: 5.3047 - val_output_A_loss: 3.1746 - val_output_B_loss: 2.1302\n",
      "Epoch 41/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.2225 - output_A_loss: 3.1380 - output_B_loss: 2.0845 - val_loss: 5.2893 - val_output_A_loss: 3.1673 - val_output_B_loss: 2.1220\n",
      "Epoch 42/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.2098 - output_A_loss: 3.1329 - output_B_loss: 2.0769 - val_loss: 5.2799 - val_output_A_loss: 3.1644 - val_output_B_loss: 2.1156\n",
      "Epoch 43/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.1968 - output_A_loss: 3.1275 - output_B_loss: 2.0693 - val_loss: 5.2650 - val_output_A_loss: 3.1566 - val_output_B_loss: 2.1085\n",
      "Epoch 44/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.1845 - output_A_loss: 3.1221 - output_B_loss: 2.0624 - val_loss: 5.2521 - val_output_A_loss: 3.1508 - val_output_B_loss: 2.1013\n",
      "Epoch 45/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.1715 - output_A_loss: 3.1166 - output_B_loss: 2.0548 - val_loss: 5.2448 - val_output_A_loss: 3.1488 - val_output_B_loss: 2.0960\n",
      "Epoch 46/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.1591 - output_A_loss: 3.1110 - output_B_loss: 2.0481 - val_loss: 5.2269 - val_output_A_loss: 3.1398 - val_output_B_loss: 2.0872\n",
      "Epoch 47/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.1466 - output_A_loss: 3.1053 - output_B_loss: 2.0412 - val_loss: 5.2160 - val_output_A_loss: 3.1340 - val_output_B_loss: 2.0819\n",
      "Epoch 48/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.1346 - output_A_loss: 3.0993 - output_B_loss: 2.0353 - val_loss: 5.2071 - val_output_A_loss: 3.1328 - val_output_B_loss: 2.0743\n",
      "Epoch 49/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.1226 - output_A_loss: 3.0934 - output_B_loss: 2.0292 - val_loss: 5.1947 - val_output_A_loss: 3.1263 - val_output_B_loss: 2.0684\n",
      "Epoch 50/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.1105 - output_A_loss: 3.0876 - output_B_loss: 2.0228 - val_loss: 5.1815 - val_output_A_loss: 3.1190 - val_output_B_loss: 2.0625\n",
      "Epoch 51/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.0980 - output_A_loss: 3.0809 - output_B_loss: 2.0170 - val_loss: 5.1695 - val_output_A_loss: 3.1125 - val_output_B_loss: 2.0570\n",
      "Epoch 52/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 5.0853 - output_A_loss: 3.0744 - output_B_loss: 2.0110 - val_loss: 5.1567 - val_output_A_loss: 3.1058 - val_output_B_loss: 2.0509\n",
      "Epoch 53/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.0739 - output_A_loss: 3.0687 - output_B_loss: 2.0052 - val_loss: 5.1507 - val_output_A_loss: 3.1035 - val_output_B_loss: 2.0471\n",
      "Epoch 54/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.0617 - output_A_loss: 3.0623 - output_B_loss: 1.9994 - val_loss: 5.1337 - val_output_A_loss: 3.0952 - val_output_B_loss: 2.0385\n",
      "Epoch 55/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.0503 - output_A_loss: 3.0559 - output_B_loss: 1.9943 - val_loss: 5.1271 - val_output_A_loss: 3.0924 - val_output_B_loss: 2.0347\n",
      "Epoch 56/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.0383 - output_A_loss: 3.0492 - output_B_loss: 1.9891 - val_loss: 5.1186 - val_output_A_loss: 3.0891 - val_output_B_loss: 2.0295\n",
      "Epoch 57/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.0271 - output_A_loss: 3.0434 - output_B_loss: 1.9837 - val_loss: 5.1030 - val_output_A_loss: 3.0799 - val_output_B_loss: 2.0231\n",
      "Epoch 58/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.0144 - output_A_loss: 3.0360 - output_B_loss: 1.9784 - val_loss: 5.0890 - val_output_A_loss: 3.0725 - val_output_B_loss: 2.0165\n",
      "Epoch 59/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 5.0035 - output_A_loss: 3.0291 - output_B_loss: 1.9744 - val_loss: 5.0775 - val_output_A_loss: 3.0654 - val_output_B_loss: 2.0121\n",
      "Epoch 60/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9917 - output_A_loss: 3.0225 - output_B_loss: 1.9692 - val_loss: 5.0719 - val_output_A_loss: 3.0635 - val_output_B_loss: 2.0084\n",
      "Epoch 61/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9813 - output_A_loss: 3.0157 - output_B_loss: 1.9655 - val_loss: 5.0564 - val_output_A_loss: 3.0540 - val_output_B_loss: 2.0024\n",
      "Epoch 62/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9695 - output_A_loss: 3.0090 - output_B_loss: 1.9605 - val_loss: 5.0480 - val_output_A_loss: 3.0486 - val_output_B_loss: 1.9994\n",
      "Epoch 63/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9587 - output_A_loss: 3.0034 - output_B_loss: 1.9553 - val_loss: 5.0592 - val_output_A_loss: 3.0583 - val_output_B_loss: 2.0009\n",
      "Epoch 64/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9479 - output_A_loss: 2.9965 - output_B_loss: 1.9514 - val_loss: 5.0292 - val_output_A_loss: 3.0395 - val_output_B_loss: 1.9897\n",
      "Epoch 65/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9368 - output_A_loss: 2.9907 - output_B_loss: 1.9461 - val_loss: 5.0153 - val_output_A_loss: 3.0314 - val_output_B_loss: 1.9839\n",
      "Epoch 66/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9269 - output_A_loss: 2.9839 - output_B_loss: 1.9430 - val_loss: 5.0148 - val_output_A_loss: 3.0321 - val_output_B_loss: 1.9827\n",
      "Epoch 67/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9164 - output_A_loss: 2.9779 - output_B_loss: 1.9385 - val_loss: 5.0014 - val_output_A_loss: 3.0237 - val_output_B_loss: 1.9777\n",
      "Epoch 68/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.9057 - output_A_loss: 2.9717 - output_B_loss: 1.9340 - val_loss: 5.0046 - val_output_A_loss: 3.0282 - val_output_B_loss: 1.9764\n",
      "Epoch 69/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8959 - output_A_loss: 2.9655 - output_B_loss: 1.9304 - val_loss: 4.9825 - val_output_A_loss: 3.0141 - val_output_B_loss: 1.9684\n",
      "Epoch 70/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8854 - output_A_loss: 2.9588 - output_B_loss: 1.9266 - val_loss: 4.9786 - val_output_A_loss: 3.0102 - val_output_B_loss: 1.9684\n",
      "Epoch 71/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8788 - output_A_loss: 2.9552 - output_B_loss: 1.9236 - val_loss: 4.9659 - val_output_A_loss: 3.0034 - val_output_B_loss: 1.9626\n",
      "Epoch 72/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8680 - output_A_loss: 2.9486 - output_B_loss: 1.9193 - val_loss: 4.9969 - val_output_A_loss: 3.0264 - val_output_B_loss: 1.9705\n",
      "Epoch 73/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8586 - output_A_loss: 2.9422 - output_B_loss: 1.9164 - val_loss: 4.9547 - val_output_A_loss: 2.9976 - val_output_B_loss: 1.9570\n",
      "Epoch 74/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.8503 - output_A_loss: 2.9379 - output_B_loss: 1.9124 - val_loss: 4.9688 - val_output_A_loss: 3.0090 - val_output_B_loss: 1.9598\n",
      "Epoch 75/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8411 - output_A_loss: 2.9321 - output_B_loss: 1.9090 - val_loss: 4.9371 - val_output_A_loss: 2.9876 - val_output_B_loss: 1.9495\n",
      "Epoch 76/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8305 - output_A_loss: 2.9257 - output_B_loss: 1.9047 - val_loss: 4.9242 - val_output_A_loss: 2.9795 - val_output_B_loss: 1.9447\n",
      "Epoch 77/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8228 - output_A_loss: 2.9211 - output_B_loss: 1.9017 - val_loss: 4.9164 - val_output_A_loss: 2.9745 - val_output_B_loss: 1.9419\n",
      "Epoch 78/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8148 - output_A_loss: 2.9160 - output_B_loss: 1.8988 - val_loss: 4.9331 - val_output_A_loss: 2.9887 - val_output_B_loss: 1.9443\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8067 - output_A_loss: 2.9110 - output_B_loss: 1.8957 - val_loss: 4.9523 - val_output_A_loss: 3.0047 - val_output_B_loss: 1.9476\n",
      "Epoch 80/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.8016 - output_A_loss: 2.9089 - output_B_loss: 1.8928 - val_loss: 4.8958 - val_output_A_loss: 2.9626 - val_output_B_loss: 1.9332\n",
      "Epoch 81/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7924 - output_A_loss: 2.9024 - output_B_loss: 1.8900 - val_loss: 4.8892 - val_output_A_loss: 2.9584 - val_output_B_loss: 1.9308\n",
      "Epoch 82/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7834 - output_A_loss: 2.8968 - output_B_loss: 1.8865 - val_loss: 4.9174 - val_output_A_loss: 2.9808 - val_output_B_loss: 1.9366\n",
      "Epoch 83/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7767 - output_A_loss: 2.8931 - output_B_loss: 1.8835 - val_loss: 4.8728 - val_output_A_loss: 2.9505 - val_output_B_loss: 1.9223\n",
      "Epoch 84/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.7672 - output_A_loss: 2.8871 - output_B_loss: 1.8801 - val_loss: 4.8707 - val_output_A_loss: 2.9496 - val_output_B_loss: 1.9211\n",
      "Epoch 85/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.7583 - output_A_loss: 2.8824 - output_B_loss: 1.8759 - val_loss: 4.8680 - val_output_A_loss: 2.9483 - val_output_B_loss: 1.9197\n",
      "Epoch 86/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7540 - output_A_loss: 2.8808 - output_B_loss: 1.8732 - val_loss: 4.8552 - val_output_A_loss: 2.9397 - val_output_B_loss: 1.9155\n",
      "Epoch 87/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7451 - output_A_loss: 2.8753 - output_B_loss: 1.8698 - val_loss: 4.8624 - val_output_A_loss: 2.9463 - val_output_B_loss: 1.9161\n",
      "Epoch 88/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7385 - output_A_loss: 2.8714 - output_B_loss: 1.8672 - val_loss: 4.8913 - val_output_A_loss: 2.9701 - val_output_B_loss: 1.9212\n",
      "Epoch 89/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.7340 - output_A_loss: 2.8688 - output_B_loss: 1.8652 - val_loss: 4.8454 - val_output_A_loss: 2.9362 - val_output_B_loss: 1.9092\n",
      "Epoch 90/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7267 - output_A_loss: 2.8644 - output_B_loss: 1.8623 - val_loss: 4.8314 - val_output_A_loss: 2.9274 - val_output_B_loss: 1.9040\n",
      "Epoch 91/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.7204 - output_A_loss: 2.8613 - output_B_loss: 1.8591 - val_loss: 4.8230 - val_output_A_loss: 2.9199 - val_output_B_loss: 1.9031\n",
      "Epoch 92/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7138 - output_A_loss: 2.8561 - output_B_loss: 1.8576 - val_loss: 4.8701 - val_output_A_loss: 2.9590 - val_output_B_loss: 1.9111\n",
      "Epoch 93/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.7043 - output_A_loss: 2.8514 - output_B_loss: 1.8530 - val_loss: 4.8158 - val_output_A_loss: 2.9164 - val_output_B_loss: 1.8993\n",
      "Epoch 94/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.6981 - output_A_loss: 2.8483 - output_B_loss: 1.8498 - val_loss: 4.8263 - val_output_A_loss: 2.9265 - val_output_B_loss: 1.8999\n",
      "Epoch 95/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6897 - output_A_loss: 2.8425 - output_B_loss: 1.8471 - val_loss: 4.8029 - val_output_A_loss: 2.9099 - val_output_B_loss: 1.8930\n",
      "Epoch 96/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6877 - output_A_loss: 2.8427 - output_B_loss: 1.8450 - val_loss: 4.7926 - val_output_A_loss: 2.9046 - val_output_B_loss: 1.8880\n",
      "Epoch 97/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6804 - output_A_loss: 2.8371 - output_B_loss: 1.8434 - val_loss: 4.7911 - val_output_A_loss: 2.9031 - val_output_B_loss: 1.8880\n",
      "Epoch 98/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.6741 - output_A_loss: 2.8334 - output_B_loss: 1.8407 - val_loss: 4.7887 - val_output_A_loss: 2.9020 - val_output_B_loss: 1.8868\n",
      "Epoch 99/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.6702 - output_A_loss: 2.8326 - output_B_loss: 1.8376 - val_loss: 4.7868 - val_output_A_loss: 2.9017 - val_output_B_loss: 1.8851\n",
      "Epoch 100/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6627 - output_A_loss: 2.8268 - output_B_loss: 1.8359 - val_loss: 4.7752 - val_output_A_loss: 2.8942 - val_output_B_loss: 1.8810\n",
      "Epoch 101/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6583 - output_A_loss: 2.8253 - output_B_loss: 1.8330 - val_loss: 4.8029 - val_output_A_loss: 2.9174 - val_output_B_loss: 1.8854\n",
      "Epoch 102/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6479 - output_A_loss: 2.8196 - output_B_loss: 1.8284 - val_loss: 4.7795 - val_output_A_loss: 2.9010 - val_output_B_loss: 1.8785\n",
      "Epoch 103/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6455 - output_A_loss: 2.8180 - output_B_loss: 1.8275 - val_loss: 4.7611 - val_output_A_loss: 2.8865 - val_output_B_loss: 1.8747\n",
      "Epoch 104/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6393 - output_A_loss: 2.8136 - output_B_loss: 1.8256 - val_loss: 4.7521 - val_output_A_loss: 2.8791 - val_output_B_loss: 1.8730\n",
      "Epoch 105/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6341 - output_A_loss: 2.8104 - output_B_loss: 1.8237 - val_loss: 4.7485 - val_output_A_loss: 2.8785 - val_output_B_loss: 1.8700\n",
      "Epoch 106/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6284 - output_A_loss: 2.8088 - output_B_loss: 1.8196 - val_loss: 4.7431 - val_output_A_loss: 2.8763 - val_output_B_loss: 1.8669\n",
      "Epoch 107/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.6195 - output_A_loss: 2.8022 - output_B_loss: 1.8173 - val_loss: 4.7556 - val_output_A_loss: 2.8841 - val_output_B_loss: 1.8715\n",
      "Epoch 108/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6169 - output_A_loss: 2.8009 - output_B_loss: 1.8160 - val_loss: 4.7831 - val_output_A_loss: 2.9083 - val_output_B_loss: 1.8748\n",
      "Epoch 109/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6114 - output_A_loss: 2.7964 - output_B_loss: 1.8150 - val_loss: 4.7527 - val_output_A_loss: 2.8846 - val_output_B_loss: 1.8681\n",
      "Epoch 110/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6093 - output_A_loss: 2.7971 - output_B_loss: 1.8122 - val_loss: 4.7630 - val_output_A_loss: 2.8913 - val_output_B_loss: 1.8717\n",
      "Epoch 111/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6067 - output_A_loss: 2.7967 - output_B_loss: 1.8100 - val_loss: 4.7230 - val_output_A_loss: 2.8637 - val_output_B_loss: 1.8594\n",
      "Epoch 112/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.6011 - output_A_loss: 2.7923 - output_B_loss: 1.8088 - val_loss: 4.7209 - val_output_A_loss: 2.8617 - val_output_B_loss: 1.8592\n",
      "Epoch 113/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5973 - output_A_loss: 2.7903 - output_B_loss: 1.8070 - val_loss: 4.7477 - val_output_A_loss: 2.8797 - val_output_B_loss: 1.8681\n",
      "Epoch 114/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5852 - output_A_loss: 2.7826 - output_B_loss: 1.8027 - val_loss: 4.7120 - val_output_A_loss: 2.8575 - val_output_B_loss: 1.8545\n",
      "Epoch 115/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5872 - output_A_loss: 2.7846 - output_B_loss: 1.8026 - val_loss: 4.7059 - val_output_A_loss: 2.8530 - val_output_B_loss: 1.8529\n",
      "Epoch 116/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5793 - output_A_loss: 2.7796 - output_B_loss: 1.7997 - val_loss: 4.7571 - val_output_A_loss: 2.8943 - val_output_B_loss: 1.8628\n",
      "Epoch 117/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5763 - output_A_loss: 2.7788 - output_B_loss: 1.7976 - val_loss: 4.7016 - val_output_A_loss: 2.8508 - val_output_B_loss: 1.8508\n",
      "Epoch 118/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5706 - output_A_loss: 2.7763 - output_B_loss: 1.7943 - val_loss: 4.7184 - val_output_A_loss: 2.8649 - val_output_B_loss: 1.8535\n",
      "Epoch 119/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5753 - output_A_loss: 2.7797 - output_B_loss: 1.7957 - val_loss: 4.7189 - val_output_A_loss: 2.8622 - val_output_B_loss: 1.8567\n",
      "Epoch 120/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5653 - output_A_loss: 2.7721 - output_B_loss: 1.7931 - val_loss: 4.7351 - val_output_A_loss: 2.8785 - val_output_B_loss: 1.8565\n",
      "Epoch 121/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5577 - output_A_loss: 2.7680 - output_B_loss: 1.7897 - val_loss: 4.7177 - val_output_A_loss: 2.8629 - val_output_B_loss: 1.8547\n",
      "Epoch 122/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5585 - output_A_loss: 2.7694 - output_B_loss: 1.7891 - val_loss: 4.7066 - val_output_A_loss: 2.8593 - val_output_B_loss: 1.8473\n",
      "Epoch 123/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5526 - output_A_loss: 2.7655 - output_B_loss: 1.7871 - val_loss: 4.6752 - val_output_A_loss: 2.8386 - val_output_B_loss: 1.8366\n",
      "Epoch 124/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5503 - output_A_loss: 2.7658 - output_B_loss: 1.7845 - val_loss: 4.6735 - val_output_A_loss: 2.8369 - val_output_B_loss: 1.8367\n",
      "Epoch 125/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5437 - output_A_loss: 2.7622 - output_B_loss: 1.7815 - val_loss: 4.6801 - val_output_A_loss: 2.8376 - val_output_B_loss: 1.8425\n",
      "Epoch 126/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5434 - output_A_loss: 2.7611 - output_B_loss: 1.7823 - val_loss: 4.6676 - val_output_A_loss: 2.8297 - val_output_B_loss: 1.8379\n",
      "Epoch 127/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5358 - output_A_loss: 2.7566 - output_B_loss: 1.7792 - val_loss: 4.6719 - val_output_A_loss: 2.8314 - val_output_B_loss: 1.8405\n",
      "Epoch 128/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5333 - output_A_loss: 2.7560 - output_B_loss: 1.7773 - val_loss: 4.6598 - val_output_A_loss: 2.8275 - val_output_B_loss: 1.8323\n",
      "Epoch 129/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5243 - output_A_loss: 2.7489 - output_B_loss: 1.7754 - val_loss: 4.7511 - val_output_A_loss: 2.8945 - val_output_B_loss: 1.8566\n",
      "Epoch 130/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5287 - output_A_loss: 2.7522 - output_B_loss: 1.7765 - val_loss: 4.6568 - val_output_A_loss: 2.8256 - val_output_B_loss: 1.8312\n",
      "Epoch 131/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5213 - output_A_loss: 2.7484 - output_B_loss: 1.7728 - val_loss: 4.8239 - val_output_A_loss: 2.9527 - val_output_B_loss: 1.8712\n",
      "Epoch 132/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5187 - output_A_loss: 2.7482 - output_B_loss: 1.7706 - val_loss: 4.6913 - val_output_A_loss: 2.8481 - val_output_B_loss: 1.8432\n",
      "Epoch 133/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5135 - output_A_loss: 2.7448 - output_B_loss: 1.7687 - val_loss: 4.6454 - val_output_A_loss: 2.8191 - val_output_B_loss: 1.8263\n",
      "Epoch 134/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5119 - output_A_loss: 2.7445 - output_B_loss: 1.7674 - val_loss: 4.6535 - val_output_A_loss: 2.8270 - val_output_B_loss: 1.8266\n",
      "Epoch 135/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.5112 - output_A_loss: 2.7441 - output_B_loss: 1.7671 - val_loss: 4.6630 - val_output_A_loss: 2.8306 - val_output_B_loss: 1.8323\n",
      "Epoch 136/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5062 - output_A_loss: 2.7410 - output_B_loss: 1.7651 - val_loss: 4.6716 - val_output_A_loss: 2.8329 - val_output_B_loss: 1.8387\n",
      "Epoch 137/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5043 - output_A_loss: 2.7407 - output_B_loss: 1.7636 - val_loss: 4.6396 - val_output_A_loss: 2.8181 - val_output_B_loss: 1.8216\n",
      "Epoch 138/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5080 - output_A_loss: 2.7451 - output_B_loss: 1.7628 - val_loss: 5.0776 - val_output_A_loss: 3.1341 - val_output_B_loss: 1.9435\n",
      "Epoch 139/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.5003 - output_A_loss: 2.7407 - output_B_loss: 1.7596 - val_loss: 4.6341 - val_output_A_loss: 2.8097 - val_output_B_loss: 1.8244\n",
      "Epoch 140/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4933 - output_A_loss: 2.7342 - output_B_loss: 1.7592 - val_loss: 4.6333 - val_output_A_loss: 2.8133 - val_output_B_loss: 1.8199\n",
      "Epoch 141/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4970 - output_A_loss: 2.7388 - output_B_loss: 1.7582 - val_loss: 4.7212 - val_output_A_loss: 2.8770 - val_output_B_loss: 1.8442\n",
      "Epoch 142/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4920 - output_A_loss: 2.7363 - output_B_loss: 1.7557 - val_loss: 4.6434 - val_output_A_loss: 2.8178 - val_output_B_loss: 1.8255\n",
      "Epoch 143/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4881 - output_A_loss: 2.7313 - output_B_loss: 1.7568 - val_loss: 4.6392 - val_output_A_loss: 2.8200 - val_output_B_loss: 1.8192\n",
      "Epoch 144/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4866 - output_A_loss: 2.7322 - output_B_loss: 1.7544 - val_loss: 4.6416 - val_output_A_loss: 2.8223 - val_output_B_loss: 1.8193\n",
      "Epoch 145/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4822 - output_A_loss: 2.7317 - output_B_loss: 1.7505 - val_loss: 4.7078 - val_output_A_loss: 2.8682 - val_output_B_loss: 1.8395\n",
      "Epoch 146/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4801 - output_A_loss: 2.7288 - output_B_loss: 1.7513 - val_loss: 4.7469 - val_output_A_loss: 2.8973 - val_output_B_loss: 1.8497\n",
      "Epoch 147/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4808 - output_A_loss: 2.7300 - output_B_loss: 1.7508 - val_loss: 4.6131 - val_output_A_loss: 2.8014 - val_output_B_loss: 1.8117\n",
      "Epoch 148/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4701 - output_A_loss: 2.7213 - output_B_loss: 1.7489 - val_loss: 4.6232 - val_output_A_loss: 2.8119 - val_output_B_loss: 1.8113\n",
      "Epoch 149/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4706 - output_A_loss: 2.7234 - output_B_loss: 1.7472 - val_loss: 4.6088 - val_output_A_loss: 2.8023 - val_output_B_loss: 1.8065\n",
      "Epoch 150/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4678 - output_A_loss: 2.7203 - output_B_loss: 1.7475 - val_loss: 4.6085 - val_output_A_loss: 2.8004 - val_output_B_loss: 1.8081\n",
      "Epoch 151/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4636 - output_A_loss: 2.7190 - output_B_loss: 1.7446 - val_loss: 4.6456 - val_output_A_loss: 2.8327 - val_output_B_loss: 1.8129\n",
      "Epoch 152/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4593 - output_A_loss: 2.7159 - output_B_loss: 1.7435 - val_loss: 4.6030 - val_output_A_loss: 2.7970 - val_output_B_loss: 1.8060\n",
      "Epoch 153/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4612 - output_A_loss: 2.7171 - output_B_loss: 1.7441 - val_loss: 4.6018 - val_output_A_loss: 2.7970 - val_output_B_loss: 1.8048\n",
      "Epoch 154/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4571 - output_A_loss: 2.7139 - output_B_loss: 1.7432 - val_loss: 4.5979 - val_output_A_loss: 2.7931 - val_output_B_loss: 1.8048\n",
      "Epoch 155/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4547 - output_A_loss: 2.7145 - output_B_loss: 1.7402 - val_loss: 4.6207 - val_output_A_loss: 2.8119 - val_output_B_loss: 1.8089\n",
      "Epoch 156/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4544 - output_A_loss: 2.7149 - output_B_loss: 1.7394 - val_loss: 4.5970 - val_output_A_loss: 2.7922 - val_output_B_loss: 1.8048\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4508 - output_A_loss: 2.7134 - output_B_loss: 1.7374 - val_loss: 4.5858 - val_output_A_loss: 2.7889 - val_output_B_loss: 1.7969\n",
      "Epoch 158/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4441 - output_A_loss: 2.7078 - output_B_loss: 1.7363 - val_loss: 4.5880 - val_output_A_loss: 2.7887 - val_output_B_loss: 1.7993\n",
      "Epoch 159/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4458 - output_A_loss: 2.7086 - output_B_loss: 1.7372 - val_loss: 4.6058 - val_output_A_loss: 2.8051 - val_output_B_loss: 1.8007\n",
      "Epoch 160/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4472 - output_A_loss: 2.7128 - output_B_loss: 1.7344 - val_loss: 4.5996 - val_output_A_loss: 2.7989 - val_output_B_loss: 1.8008\n",
      "Epoch 161/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4381 - output_A_loss: 2.7034 - output_B_loss: 1.7347 - val_loss: 4.6348 - val_output_A_loss: 2.8272 - val_output_B_loss: 1.8076\n",
      "Epoch 162/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4404 - output_A_loss: 2.7071 - output_B_loss: 1.7333 - val_loss: 4.5982 - val_output_A_loss: 2.7916 - val_output_B_loss: 1.8067\n",
      "Epoch 163/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4345 - output_A_loss: 2.7052 - output_B_loss: 1.7292 - val_loss: 4.5783 - val_output_A_loss: 2.7826 - val_output_B_loss: 1.7957\n",
      "Epoch 164/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4312 - output_A_loss: 2.7023 - output_B_loss: 1.7289 - val_loss: 4.5744 - val_output_A_loss: 2.7790 - val_output_B_loss: 1.7954\n",
      "Epoch 165/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4343 - output_A_loss: 2.7047 - output_B_loss: 1.7297 - val_loss: 4.6521 - val_output_A_loss: 2.8291 - val_output_B_loss: 1.8230\n",
      "Epoch 166/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.4308 - output_A_loss: 2.7035 - output_B_loss: 1.7272 - val_loss: 4.5937 - val_output_A_loss: 2.7945 - val_output_B_loss: 1.7993\n",
      "Epoch 167/1000\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 4.4242 - output_A_loss: 2.6961 - output_B_loss: 1.7282 - val_loss: 4.6119 - val_output_A_loss: 2.8121 - val_output_B_loss: 1.7997\n",
      "Epoch 168/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4288 - output_A_loss: 2.7007 - output_B_loss: 1.7282 - val_loss: 4.6071 - val_output_A_loss: 2.8037 - val_output_B_loss: 1.8034\n",
      "Epoch 169/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4258 - output_A_loss: 2.6980 - output_B_loss: 1.7278 - val_loss: 4.5671 - val_output_A_loss: 2.7772 - val_output_B_loss: 1.7899\n",
      "Epoch 170/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4196 - output_A_loss: 2.6940 - output_B_loss: 1.7255 - val_loss: 4.5901 - val_output_A_loss: 2.7862 - val_output_B_loss: 1.8039\n",
      "Epoch 171/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4243 - output_A_loss: 2.6999 - output_B_loss: 1.7243 - val_loss: 4.5791 - val_output_A_loss: 2.7882 - val_output_B_loss: 1.7909\n",
      "Epoch 172/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4179 - output_A_loss: 2.6942 - output_B_loss: 1.7236 - val_loss: 4.5782 - val_output_A_loss: 2.7871 - val_output_B_loss: 1.7911\n",
      "Epoch 173/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4144 - output_A_loss: 2.6944 - output_B_loss: 1.7201 - val_loss: 4.5656 - val_output_A_loss: 2.7749 - val_output_B_loss: 1.7907\n",
      "Epoch 174/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4098 - output_A_loss: 2.6904 - output_B_loss: 1.7194 - val_loss: 4.6199 - val_output_A_loss: 2.8205 - val_output_B_loss: 1.7995\n",
      "Epoch 175/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4086 - output_A_loss: 2.6894 - output_B_loss: 1.7192 - val_loss: 4.6771 - val_output_A_loss: 2.8632 - val_output_B_loss: 1.8139\n",
      "Epoch 176/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4109 - output_A_loss: 2.6900 - output_B_loss: 1.7209 - val_loss: 4.6667 - val_output_A_loss: 2.8447 - val_output_B_loss: 1.8220\n",
      "Epoch 177/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4076 - output_A_loss: 2.6910 - output_B_loss: 1.7166 - val_loss: 4.5804 - val_output_A_loss: 2.7913 - val_output_B_loss: 1.7890\n",
      "Epoch 178/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4039 - output_A_loss: 2.6882 - output_B_loss: 1.7157 - val_loss: 4.5666 - val_output_A_loss: 2.7787 - val_output_B_loss: 1.7878\n",
      "Epoch 179/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4042 - output_A_loss: 2.6844 - output_B_loss: 1.7198 - val_loss: 4.5547 - val_output_A_loss: 2.7741 - val_output_B_loss: 1.7806\n",
      "Epoch 180/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4025 - output_A_loss: 2.6860 - output_B_loss: 1.7165 - val_loss: 4.5642 - val_output_A_loss: 2.7815 - val_output_B_loss: 1.7828\n",
      "Epoch 181/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4004 - output_A_loss: 2.6869 - output_B_loss: 1.7135 - val_loss: 4.6288 - val_output_A_loss: 2.8079 - val_output_B_loss: 1.8209\n",
      "Epoch 182/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.4027 - output_A_loss: 2.6868 - output_B_loss: 1.7159 - val_loss: 4.6485 - val_output_A_loss: 2.8410 - val_output_B_loss: 1.8076\n",
      "Epoch 183/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3975 - output_A_loss: 2.6847 - output_B_loss: 1.7129 - val_loss: 4.5530 - val_output_A_loss: 2.7723 - val_output_B_loss: 1.7806\n",
      "Epoch 184/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3989 - output_A_loss: 2.6847 - output_B_loss: 1.7142 - val_loss: 4.5512 - val_output_A_loss: 2.7652 - val_output_B_loss: 1.7860\n",
      "Epoch 185/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3934 - output_A_loss: 2.6800 - output_B_loss: 1.7134 - val_loss: 4.5503 - val_output_A_loss: 2.7663 - val_output_B_loss: 1.7840\n",
      "Epoch 186/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3907 - output_A_loss: 2.6809 - output_B_loss: 1.7098 - val_loss: 4.5815 - val_output_A_loss: 2.7941 - val_output_B_loss: 1.7873\n",
      "Epoch 187/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3923 - output_A_loss: 2.6809 - output_B_loss: 1.7114 - val_loss: 4.5818 - val_output_A_loss: 2.7961 - val_output_B_loss: 1.7857\n",
      "Epoch 188/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3947 - output_A_loss: 2.6840 - output_B_loss: 1.7108 - val_loss: 4.5499 - val_output_A_loss: 2.7701 - val_output_B_loss: 1.7798\n",
      "Epoch 189/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3866 - output_A_loss: 2.6780 - output_B_loss: 1.7086 - val_loss: 4.5429 - val_output_A_loss: 2.7663 - val_output_B_loss: 1.7766\n",
      "Epoch 190/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3872 - output_A_loss: 2.6792 - output_B_loss: 1.7080 - val_loss: 4.5591 - val_output_A_loss: 2.7761 - val_output_B_loss: 1.7831\n",
      "Epoch 191/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3877 - output_A_loss: 2.6791 - output_B_loss: 1.7086 - val_loss: 4.6510 - val_output_A_loss: 2.8511 - val_output_B_loss: 1.7999\n",
      "Epoch 192/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3851 - output_A_loss: 2.6784 - output_B_loss: 1.7068 - val_loss: 4.5751 - val_output_A_loss: 2.7979 - val_output_B_loss: 1.7772\n",
      "Epoch 193/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3822 - output_A_loss: 2.6760 - output_B_loss: 1.7062 - val_loss: 4.5410 - val_output_A_loss: 2.7689 - val_output_B_loss: 1.7721\n",
      "Epoch 194/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3804 - output_A_loss: 2.6734 - output_B_loss: 1.7070 - val_loss: 4.5480 - val_output_A_loss: 2.7708 - val_output_B_loss: 1.7772\n",
      "Epoch 195/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3804 - output_A_loss: 2.6731 - output_B_loss: 1.7072 - val_loss: 4.5370 - val_output_A_loss: 2.7644 - val_output_B_loss: 1.7726\n",
      "Epoch 196/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3802 - output_A_loss: 2.6726 - output_B_loss: 1.7076 - val_loss: 4.5863 - val_output_A_loss: 2.8061 - val_output_B_loss: 1.7802\n",
      "Epoch 197/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3750 - output_A_loss: 2.6721 - output_B_loss: 1.7029 - val_loss: 4.5243 - val_output_A_loss: 2.7591 - val_output_B_loss: 1.7652\n",
      "Epoch 198/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3719 - output_A_loss: 2.6700 - output_B_loss: 1.7019 - val_loss: 4.5504 - val_output_A_loss: 2.7809 - val_output_B_loss: 1.7695\n",
      "Epoch 199/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3725 - output_A_loss: 2.6700 - output_B_loss: 1.7025 - val_loss: 4.5279 - val_output_A_loss: 2.7613 - val_output_B_loss: 1.7666\n",
      "Epoch 200/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3677 - output_A_loss: 2.6683 - output_B_loss: 1.6994 - val_loss: 4.5314 - val_output_A_loss: 2.7640 - val_output_B_loss: 1.7673\n",
      "Epoch 201/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.3653 - output_A_loss: 2.6667 - output_B_loss: 1.6986 - val_loss: 4.5289 - val_output_A_loss: 2.7577 - val_output_B_loss: 1.7712\n",
      "Epoch 202/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3675 - output_A_loss: 2.6704 - output_B_loss: 1.6970 - val_loss: 4.5657 - val_output_A_loss: 2.7819 - val_output_B_loss: 1.7838\n",
      "Epoch 203/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3734 - output_A_loss: 2.6727 - output_B_loss: 1.7007 - val_loss: 4.5280 - val_output_A_loss: 2.7626 - val_output_B_loss: 1.7654\n",
      "Epoch 204/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3609 - output_A_loss: 2.6612 - output_B_loss: 1.6997 - val_loss: 4.5216 - val_output_A_loss: 2.7572 - val_output_B_loss: 1.7644\n",
      "Epoch 205/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3629 - output_A_loss: 2.6670 - output_B_loss: 1.6959 - val_loss: 4.5601 - val_output_A_loss: 2.7775 - val_output_B_loss: 1.7825\n",
      "Epoch 206/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3652 - output_A_loss: 2.6672 - output_B_loss: 1.6980 - val_loss: 4.5329 - val_output_A_loss: 2.7659 - val_output_B_loss: 1.7670\n",
      "Epoch 207/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3619 - output_A_loss: 2.6655 - output_B_loss: 1.6964 - val_loss: 4.5347 - val_output_A_loss: 2.7702 - val_output_B_loss: 1.7645\n",
      "Epoch 208/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3623 - output_A_loss: 2.6651 - output_B_loss: 1.6972 - val_loss: 4.5433 - val_output_A_loss: 2.7767 - val_output_B_loss: 1.7666\n",
      "Epoch 209/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3531 - output_A_loss: 2.6549 - output_B_loss: 1.6982 - val_loss: 4.5156 - val_output_A_loss: 2.7524 - val_output_B_loss: 1.7632\n",
      "Epoch 210/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3540 - output_A_loss: 2.6592 - output_B_loss: 1.6949 - val_loss: 4.5278 - val_output_A_loss: 2.7620 - val_output_B_loss: 1.7657\n",
      "Epoch 211/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3543 - output_A_loss: 2.6611 - output_B_loss: 1.6933 - val_loss: 4.5575 - val_output_A_loss: 2.7851 - val_output_B_loss: 1.7724\n",
      "Epoch 212/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3523 - output_A_loss: 2.6610 - output_B_loss: 1.6913 - val_loss: 4.5145 - val_output_A_loss: 2.7543 - val_output_B_loss: 1.7602\n",
      "Epoch 213/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3514 - output_A_loss: 2.6595 - output_B_loss: 1.6919 - val_loss: 4.5218 - val_output_A_loss: 2.7614 - val_output_B_loss: 1.7605\n",
      "Epoch 214/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3504 - output_A_loss: 2.6578 - output_B_loss: 1.6926 - val_loss: 4.5166 - val_output_A_loss: 2.7585 - val_output_B_loss: 1.7581\n",
      "Epoch 215/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3482 - output_A_loss: 2.6575 - output_B_loss: 1.6907 - val_loss: 4.5251 - val_output_A_loss: 2.7652 - val_output_B_loss: 1.7599\n",
      "Epoch 216/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3463 - output_A_loss: 2.6545 - output_B_loss: 1.6917 - val_loss: 4.5313 - val_output_A_loss: 2.7711 - val_output_B_loss: 1.7602\n",
      "Epoch 217/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3491 - output_A_loss: 2.6579 - output_B_loss: 1.6912 - val_loss: 4.5252 - val_output_A_loss: 2.7582 - val_output_B_loss: 1.7670\n",
      "Epoch 218/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3469 - output_A_loss: 2.6559 - output_B_loss: 1.6910 - val_loss: 4.5081 - val_output_A_loss: 2.7484 - val_output_B_loss: 1.7597\n",
      "Epoch 219/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3435 - output_A_loss: 2.6560 - output_B_loss: 1.6876 - val_loss: 4.5104 - val_output_A_loss: 2.7533 - val_output_B_loss: 1.7571\n",
      "Epoch 220/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3436 - output_A_loss: 2.6554 - output_B_loss: 1.6882 - val_loss: 4.5291 - val_output_A_loss: 2.7639 - val_output_B_loss: 1.7652\n",
      "Epoch 221/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3437 - output_A_loss: 2.6535 - output_B_loss: 1.6903 - val_loss: 4.5148 - val_output_A_loss: 2.7566 - val_output_B_loss: 1.7582\n",
      "Epoch 222/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3400 - output_A_loss: 2.6512 - output_B_loss: 1.6888 - val_loss: 4.5055 - val_output_A_loss: 2.7474 - val_output_B_loss: 1.7581\n",
      "Epoch 223/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3334 - output_A_loss: 2.6502 - output_B_loss: 1.6833 - val_loss: 4.5226 - val_output_A_loss: 2.7688 - val_output_B_loss: 1.7538\n",
      "Epoch 224/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.3359 - output_A_loss: 2.6491 - output_B_loss: 1.6869 - val_loss: 4.5050 - val_output_A_loss: 2.7533 - val_output_B_loss: 1.7517\n",
      "Epoch 225/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3412 - output_A_loss: 2.6534 - output_B_loss: 1.6878 - val_loss: 4.5097 - val_output_A_loss: 2.7541 - val_output_B_loss: 1.7555\n",
      "Epoch 226/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3363 - output_A_loss: 2.6519 - output_B_loss: 1.6844 - val_loss: 4.5012 - val_output_A_loss: 2.7452 - val_output_B_loss: 1.7560\n",
      "Epoch 227/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3394 - output_A_loss: 2.6523 - output_B_loss: 1.6871 - val_loss: 4.5379 - val_output_A_loss: 2.7809 - val_output_B_loss: 1.7570\n",
      "Epoch 228/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3263 - output_A_loss: 2.6456 - output_B_loss: 1.6808 - val_loss: 4.4990 - val_output_A_loss: 2.7479 - val_output_B_loss: 1.7511\n",
      "Epoch 229/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3310 - output_A_loss: 2.6493 - output_B_loss: 1.6817 - val_loss: 4.4974 - val_output_A_loss: 2.7436 - val_output_B_loss: 1.7539\n",
      "Epoch 230/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3314 - output_A_loss: 2.6452 - output_B_loss: 1.6861 - val_loss: 4.5049 - val_output_A_loss: 2.7501 - val_output_B_loss: 1.7548\n",
      "Epoch 231/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3294 - output_A_loss: 2.6470 - output_B_loss: 1.6823 - val_loss: 4.5368 - val_output_A_loss: 2.7740 - val_output_B_loss: 1.7628\n",
      "Epoch 232/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3285 - output_A_loss: 2.6473 - output_B_loss: 1.6812 - val_loss: 4.6372 - val_output_A_loss: 2.8478 - val_output_B_loss: 1.7894\n",
      "Epoch 233/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3262 - output_A_loss: 2.6443 - output_B_loss: 1.6819 - val_loss: 4.4972 - val_output_A_loss: 2.7479 - val_output_B_loss: 1.7493\n",
      "Epoch 234/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3247 - output_A_loss: 2.6429 - output_B_loss: 1.6819 - val_loss: 4.5243 - val_output_A_loss: 2.7640 - val_output_B_loss: 1.7604\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 2s 10ms/step - loss: 4.3250 - output_A_loss: 2.6442 - output_B_loss: 1.6808 - val_loss: 4.5396 - val_output_A_loss: 2.7710 - val_output_B_loss: 1.7686\n",
      "Epoch 236/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3214 - output_A_loss: 2.6414 - output_B_loss: 1.6800 - val_loss: 4.5060 - val_output_A_loss: 2.7565 - val_output_B_loss: 1.7495\n",
      "Epoch 237/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3233 - output_A_loss: 2.6441 - output_B_loss: 1.6792 - val_loss: 4.5118 - val_output_A_loss: 2.7647 - val_output_B_loss: 1.7472\n",
      "Epoch 238/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3225 - output_A_loss: 2.6441 - output_B_loss: 1.6784 - val_loss: 4.4930 - val_output_A_loss: 2.7448 - val_output_B_loss: 1.7482\n",
      "Epoch 239/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3194 - output_A_loss: 2.6423 - output_B_loss: 1.6772 - val_loss: 4.4945 - val_output_A_loss: 2.7405 - val_output_B_loss: 1.7541\n",
      "Epoch 240/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3218 - output_A_loss: 2.6446 - output_B_loss: 1.6772 - val_loss: 4.4889 - val_output_A_loss: 2.7436 - val_output_B_loss: 1.7453\n",
      "Epoch 241/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3170 - output_A_loss: 2.6390 - output_B_loss: 1.6780 - val_loss: 4.4971 - val_output_A_loss: 2.7495 - val_output_B_loss: 1.7477\n",
      "Epoch 242/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3158 - output_A_loss: 2.6399 - output_B_loss: 1.6759 - val_loss: 4.5101 - val_output_A_loss: 2.7616 - val_output_B_loss: 1.7485\n",
      "Epoch 243/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3169 - output_A_loss: 2.6409 - output_B_loss: 1.6760 - val_loss: 4.5069 - val_output_A_loss: 2.7585 - val_output_B_loss: 1.7484\n",
      "Epoch 244/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3109 - output_A_loss: 2.6367 - output_B_loss: 1.6742 - val_loss: 4.4966 - val_output_A_loss: 2.7498 - val_output_B_loss: 1.7468\n",
      "Epoch 245/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3120 - output_A_loss: 2.6373 - output_B_loss: 1.6747 - val_loss: 4.4844 - val_output_A_loss: 2.7405 - val_output_B_loss: 1.7440\n",
      "Epoch 246/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3130 - output_A_loss: 2.6370 - output_B_loss: 1.6761 - val_loss: 4.4894 - val_output_A_loss: 2.7429 - val_output_B_loss: 1.7465\n",
      "Epoch 247/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3111 - output_A_loss: 2.6357 - output_B_loss: 1.6755 - val_loss: 4.4997 - val_output_A_loss: 2.7534 - val_output_B_loss: 1.7463\n",
      "Epoch 248/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3079 - output_A_loss: 2.6330 - output_B_loss: 1.6749 - val_loss: 4.4959 - val_output_A_loss: 2.7472 - val_output_B_loss: 1.7487\n",
      "Epoch 249/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.3047 - output_A_loss: 2.6317 - output_B_loss: 1.6731 - val_loss: 4.5241 - val_output_A_loss: 2.7734 - val_output_B_loss: 1.7506\n",
      "Epoch 250/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3080 - output_A_loss: 2.6357 - output_B_loss: 1.6724 - val_loss: 4.5702 - val_output_A_loss: 2.8106 - val_output_B_loss: 1.7597\n",
      "Epoch 251/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3081 - output_A_loss: 2.6343 - output_B_loss: 1.6738 - val_loss: 4.5496 - val_output_A_loss: 2.7887 - val_output_B_loss: 1.7609\n",
      "Epoch 252/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3016 - output_A_loss: 2.6312 - output_B_loss: 1.6704 - val_loss: 4.4900 - val_output_A_loss: 2.7443 - val_output_B_loss: 1.7457\n",
      "Epoch 253/1000\n",
      "175/175 [==============================] - 2s 9ms/step - loss: 4.3006 - output_A_loss: 2.6318 - output_B_loss: 1.6688 - val_loss: 4.5824 - val_output_A_loss: 2.8215 - val_output_B_loss: 1.7609\n",
      "Epoch 254/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.3019 - output_A_loss: 2.6297 - output_B_loss: 1.6722 - val_loss: 4.7594 - val_output_A_loss: 2.9422 - val_output_B_loss: 1.8172\n",
      "Epoch 255/1000\n",
      "175/175 [==============================] - 2s 10ms/step - loss: 4.3042 - output_A_loss: 2.6340 - output_B_loss: 1.6702 - val_loss: 4.5077 - val_output_A_loss: 2.7611 - val_output_B_loss: 1.7467\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\",\n",
    "                                                save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(train, epochs=1000,\n",
    "                    validation_data = valid,\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "# model = keras.models.load_model(\"my_keras_model.h5\") # roll back to best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 1s 2ms/step - loss: 4.4284 - output_A_loss: 2.6921 - output_B_loss: 1.7363\n"
     ]
    }
   ],
   "source": [
    "total_loss, output_A_loss, output_B_loss = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_start_A = tf.reshape(X[0:20,:],[1,20,31])\n",
    "X_start_B = tf.reshape(X[20,:],[1,1,31])\n",
    "y_pred_A, y_pred_B = model.predict((X_start_A, X_start_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_A = y_pred_A.reshape([30,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00067716, 0.00190915, 0.00152396, 0.0103321 , 0.01087172,\n",
       "       0.01535911, 0.02206642, 0.03449211, 0.04800986, 0.06169345,\n",
       "       0.07379999, 0.09606186, 0.0977999 , 0.11237505, 0.08416948,\n",
       "       0.09317786, 0.06048174, 0.05260655, 0.04169814, 0.02771354,\n",
       "       0.01801369, 0.01380401, 0.00901957, 0.00418178, 0.00273614,\n",
       "       0.00162271, 0.00138894, 0.00104527, 0.00056717, 0.0008017 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.6131772e-03, 1.5351252e-03, 1.9504228e-03, 4.5388993e-03,\n",
       "        2.3485422e-01, 2.8297099e-01, 7.5206679e-04, 4.2217756e-03,\n",
       "        6.5058291e-02, 1.7451659e-01, 1.8333592e-01, 6.5362104e-04,\n",
       "        2.9205132e-04, 3.6818638e-02, 1.6233191e-03, 5.3966208e-04,\n",
       "        3.1124626e-04, 2.4665165e-05, 3.9106247e-04, 3.7426283e-04,\n",
       "        1.5308102e-05, 1.7074865e-04, 2.5440744e-05, 1.7445337e-04,\n",
       "        2.0087395e-04, 2.2326725e-05, 1.5282101e-04, 2.5725600e-04,\n",
       "        2.3929816e-04, 3.6562790e-04]], dtype=float32)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_A_class_random = np.random.choice(30, 1, p=y_pred_A)[0]\n",
    "pred_A_class_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_A_class_max = np.where(y_pred_A == np.max(y_pred_A))[0][0]\n",
    "pred_A_class_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04806693, 0.0479217 , 0.0482955 , 0.04863629, 0.04889583,\n",
       "        0.04933615, 0.04949446, 0.04913004, 0.04967229, 0.04977289,\n",
       "        0.04988996, 0.05001303, 0.05070541, 0.05095737, 0.05157588,\n",
       "        0.05172214, 0.05159759, 0.05125884, 0.05164228, 0.05141547]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_model.predict((X_start_A, X_start_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00571418, 0.00576093, 0.00670105, 0.00754772, 0.00909929,\n",
       "        0.01285915, 0.01515933, 0.01924153, 0.02778253, 0.03087712,\n",
       "        0.03801217, 0.04425151, 0.04236898, 0.04851086, 0.04146721,\n",
       "        0.04249327, 0.0456176 , 0.05001752, 0.05092429, 0.05524354,\n",
       "        0.04319492, 0.04571097, 0.04449021, 0.04673455, 0.04125574,\n",
       "        0.04386832, 0.0410103 , 0.03868463, 0.02597555, 0.02942494]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_model.predict(X_start_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 3.0385\n"
     ]
    }
   ],
   "source": [
    "out_A = tf.reshape(X[20,:-1],[1,30])\n",
    "history = sub_model.fit(X_start_A,out_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00562455, 0.00574463, 0.00668056, 0.00753776, 0.0091731 ,\n",
       "       0.01257379, 0.01475128, 0.01957747, 0.02798583, 0.03070259,\n",
       "       0.03777093, 0.0445409 , 0.04266191, 0.04840747, 0.04168428,\n",
       "       0.04331362, 0.04564666, 0.0493383 , 0.05078552, 0.05478575,\n",
       "       0.04264643, 0.04581724, 0.04445539, 0.04604835, 0.04204214,\n",
       "       0.04367106, 0.04185832, 0.03850069, 0.02602573, 0.02964774],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_start_A = tf.reshape(X[9000:9020,:],[1,20,31])\n",
    "output_A = sub_model.predict(X_start_A).reshape([30,])\n",
    "output_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_A_class_random = np.random.choice(30, 1, p=output_A)[0]\n",
    "pred_A_class_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 31), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = tf.reshape(tf.one_hot(pred_A_class_random, 30),[1,1,30])\n",
    "out_0 = tf.concat((one_hot,[[[0]]]),2)\n",
    "out_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 21, 31), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = X_start_A\n",
    "sequence = tf.concat((sequence,out_0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_A: [[0.0002765  0.00043334 0.00040457 0.00069469 0.00051682 0.00046351\n",
      "  0.00057519 0.00063459 0.00068334 0.00137723 0.00206947 0.00411383\n",
      "  0.00614368 0.0085591  0.01278596 0.01632692 0.0214982  0.03857156\n",
      "  0.04984158 0.06143961 0.06356119 0.08601837 0.08164802 0.09877734\n",
      "  0.09345005 0.08831961 0.08210105 0.07336163 0.04988647 0.05546666]] y_pred_B: [[6.8537161e-06 1.4443988e-04 8.0808473e-05 3.4123881e-05 2.4863728e-05\n",
      "  7.1276609e-06 1.6160871e-04 4.2995796e-04 2.9981358e-04 5.3690420e-04\n",
      "  4.2272732e-04 2.4410681e-04 2.0895947e-03 3.9483807e-03 2.9393965e-03\n",
      "  3.1873684e-03 6.3587935e-03 2.6323944e-01 1.4912690e-01 4.8175328e-03\n",
      "  9.2510357e-03 6.9997534e-02 2.1094139e-01 1.6499990e-01 1.9481773e-02\n",
      "  1.1417845e-02 7.1839094e-02 2.6789189e-03 9.8583265e-04 3.0596548e-04]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_A, y_pred_B = model.predict((X_start_A,out_0))\n",
    "print('y_pred_A:',y_pred_A, 'y_pred_B:',y_pred_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_B = y_pred_B.reshape([30,])\n",
    "pred_B_class_random = np.random.choice(30, 1, p=output_B)[0]\n",
    "pred_B_class_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 31), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = tf.reshape(tf.one_hot(pred_B_class_random, 30),[1,1,30])\n",
    "out_1 = tf.concat((one_hot,[[[1]]]),2)\n",
    "out_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = tf.concat((sequence,out_1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 22, 31])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 20, 31])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_start_A = sequence[:,-20:,:]\n",
    "X_start_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(initial,seq_length):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    initial -- initial sequence of shape (1,20,31) (1 sample, sequence of length 20, vector fearure: one-hot(30);cantus(0),counter(1))\n",
    "    seq_length -- # pairs of notes generated\n",
    "    \n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    sequence = initial\n",
    "    for i in range(seq_length):\n",
    "        output_A = sub_model.predict(initial).reshape([30,])\n",
    "        pred_A_class_random = np.random.choice(30, 1, p=output_A)[0]\n",
    "\n",
    "        one_hot = tf.reshape(tf.one_hot(pred_A_class_random, 30),[1,1,30])\n",
    "        out_0 = tf.concat((one_hot,[[[0]]]),2)\n",
    "        sequence = tf.concat((sequence,out_0),1)\n",
    "\n",
    "        y_pred_A, y_pred_B = model.predict((X_start_A,out_0))\n",
    "        output_B = y_pred_B.reshape([30,])\n",
    "        pred_B_class_random = np.random.choice(30, 1, p=output_B)[0]\n",
    "\n",
    "        one_hot = tf.reshape(tf.one_hot(pred_B_class_random, 30),[1,1,30])\n",
    "        out_1 = tf.concat((one_hot,[[[1]]]),2)\n",
    "        sequence = tf.concat((sequence,out_1),1)\n",
    "\n",
    "        initial = sequence[:,-20:,:]\n",
    "        \n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_start_A = tf.reshape(X[9000:9020,:],[1,20,31])\n",
    "seq_length = 10\n",
    "sequence = generate_sequence(X_start_A,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 40, 31), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sequence = sequence[:,20:,:]\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 31)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tf.reshape(sequence,[20+2*seq_length,31])\n",
    "sequence = np.array(sequence)\n",
    "sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(sequence[1,:-1] == 1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "row,col = sequence.shape\n",
    "cantus_lst = [];\n",
    "counter_lst = [];\n",
    "for i in range(row):\n",
    "    clas = np.where(sequence[i,:-1] == 1)[0][0]\n",
    "    if sequence[i,-1] == 0:\n",
    "        cantus_lst.append(clas+43)\n",
    "    elif sequence[i,-1] == 1:\n",
    "        counter_lst.append(clas+55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63,\n",
       " 62,\n",
       " 58,\n",
       " 56,\n",
       " 59,\n",
       " 62,\n",
       " 61,\n",
       " 59,\n",
       " 62,\n",
       " 72,\n",
       " 65,\n",
       " 61,\n",
       " 58,\n",
       " 67,\n",
       " 62,\n",
       " 72,\n",
       " 46,\n",
       " 51,\n",
       " 62,\n",
       " 64]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cantus_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67,\n",
       " 65,\n",
       " 67,\n",
       " 64,\n",
       " 62,\n",
       " 70,\n",
       " 69,\n",
       " 68,\n",
       " 71,\n",
       " 75,\n",
       " 74,\n",
       " 69,\n",
       " 67,\n",
       " 76,\n",
       " 66,\n",
       " 81,\n",
       " 74,\n",
       " 63,\n",
       " 69,\n",
       " 72]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preset Piano Merlin for piano\n",
      "Using preset Piano Merlin for piano\n"
     ]
    }
   ],
   "source": [
    "s = Session()\n",
    "s.tempo = 180\n",
    "piano1 = s.new_part(\"piano\")\n",
    "piano2 = s.new_part(\"piano\")\n",
    "\n",
    "def cantus():\n",
    "    for i in cantus_lst:\n",
    "        piano2.play_note(i,1,4)\n",
    "        \n",
    "def counter():\n",
    "    for i in counter_lst:\n",
    "        piano1.play_note(i,1,4)\n",
    "        \n",
    "        \n",
    "s.fast_forward_to_beat(100)\n",
    "\n",
    "s.start_transcribing()\n",
    "s.fork(counter)\n",
    "s.fork(cantus)\n",
    "s.wait_for_children_to_finish()\n",
    "performance = s.stop_transcribing()\n",
    "performance.to_score(title = \"First Species Counterpoint\", composer = \"My programme\",time_signature = \"4/4\").show_xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  3,  9,  8,  3,  8,  8,  9,  9,  3,  9,  8,  9,  9,  4,  9, 28,\n",
       "       12,  7,  8], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(counter_lst) - np.array(cantus_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1,  -4,  -2,   3,   3,  -1,  -2,   3,  10,  -7,  -4,  -3,   9,\n",
       "        -5,  10, -26,   5,  11,   2], dtype=int64)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(cantus_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2,   2,  -3,  -2,   8,  -1,  -1,   3,   4,  -1,  -5,  -2,   9,\n",
       "       -10,  15,  -7, -11,   6,   3], dtype=int64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(counter_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
